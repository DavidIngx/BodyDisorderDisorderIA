{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset (Load , exploration and  Cleaning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# calculations and Dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# plot facial expression \n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "# Paquetes necesarios para la morfología matemática\n",
    "from skimage.morphology import erosion, dilation, opening, closing\n",
    "# Elementos estructurales\n",
    "from skimage.morphology import disk, diamond, ball, rectangle\n",
    "# Paquetes necesarios para la conversión de imágenes de color a escala de grises\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import gaussian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset_facial_expression = pd.read_csv(\"../fer2013.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the top five\n",
    "dataset_facial_expression.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>6</td>\n",
       "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35883</th>\n",
       "      <td>3</td>\n",
       "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>0</td>\n",
       "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>3</td>\n",
       "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>2</td>\n",
       "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion                                             pixels        Usage\n",
       "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
       "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
       "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
       "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
       "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the last five\n",
    "dataset_facial_expression.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting missing, nan or null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35887.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.323265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.873819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            emotion\n",
       "count  35887.000000\n",
       "mean       3.323265\n",
       "std        1.873819\n",
       "min        0.000000\n",
       "25%        2.000000\n",
       "50%        3.000000\n",
       "75%        5.000000\n",
       "max        6.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics: Numeric data\n",
    "dataset_facial_expression.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset_facial_expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35887"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_facial_expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      "emotion    35887 non-null int64\n",
      "pixels     35887 non-null object\n",
      "Usage      35887 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_facial_expression.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>101 89 107 102 92 92 95 101 113 112 103 116 13...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>40 35 40 65 89 110 128 137 145 153 156 158 159...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>34 52 33 53 73 65 45 38 53 63 68 63 59 51 39 2...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>235 236 233 141 92 116 103 80 67 75 71 55 65 6...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>104 74 72 74 72 70 69 69 71 69 72 70 69 72 69 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>13 15 16 17 16 18 14 18 24 31 38 43 43 45 55 6...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>83 64 60 59 60 53 45 50 54 47 40 37 44 48 48 5...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>255 239 107 55 45 61 57 51 65 80 92 96 99 101 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>202 204 201 194 212 202 128 50 19 23 20 9 8 13...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>193 193 194 194 194 196 196 196 197 197 196 19...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>254 254 251 255 124 0 4 29 58 102 186 194 188 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>179 180 180 180 180 182 181 182 187 157 164 18...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>216 216 215 213 212 210 207 204 204 202 201 20...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>242 242 242 241 241 245 72 3 7 8 12 9 17 16 18...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>119 119 119 118 83 67 66 66 67 69 72 74 73 73 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>255 254 250 255 195 100 108 135 147 153 157 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>30 29 33 31 31 29 25 26 26 28 30 31 35 38 43 4...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>213 214 217 219 222 226 228 229 227 231 185 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>184 191 156 198 153 160 133 155 77 93 145 149 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>248 247 247 251 220 198 200 207 206 202 196 19...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>1 3 3 3 2 36 72 58 33 53 60 66 68 71 75 75 81 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>36 32 31 33 32 38 25 20 20 15 21 35 48 73 111 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>16 10 24 35 60 106 147 174 186 193 198 202 208...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>67 68 69 67 67 63 70 71 67 104 137 153 177 185...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>155 161 163 155 145 140 133 154 158 98 49 41 3...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>177 169 141 144 148 130 122 131 113 124 104 10...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>32 33 33 34 30 33 45 74 90 86 89 95 95 95 105 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>153 182 183 190 203 211 203 197 197 192 192 19...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>182 64 53 65 35 31 37 46 46 51 59 64 68 79 90 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>29 67 114 138 157 172 178 182 184 180 178 179 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35857</th>\n",
       "      <td>5</td>\n",
       "      <td>254 254 254 252 250 248 245 224 228 233 172 18...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35858</th>\n",
       "      <td>6</td>\n",
       "      <td>118 118 120 118 115 112 130 67 5 24 19 13 16 2...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35859</th>\n",
       "      <td>3</td>\n",
       "      <td>233 224 215 209 225 218 206 204 196 193 212 17...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35860</th>\n",
       "      <td>4</td>\n",
       "      <td>76 76 79 80 81 83 88 89 89 89 89 87 93 97 100 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35861</th>\n",
       "      <td>0</td>\n",
       "      <td>28 32 35 51 65 76 70 82 93 97 110 127 131 133 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35862</th>\n",
       "      <td>0</td>\n",
       "      <td>105 104 119 120 119 118 122 116 114 115 113 11...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35863</th>\n",
       "      <td>4</td>\n",
       "      <td>47 45 43 43 41 38 166 191 218 213 207 154 135 ...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35864</th>\n",
       "      <td>6</td>\n",
       "      <td>44 49 58 41 49 54 33 46 81 105 123 133 90 52 5...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35865</th>\n",
       "      <td>4</td>\n",
       "      <td>51 75 80 103 75 76 76 64 89 113 111 101 120 12...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35866</th>\n",
       "      <td>6</td>\n",
       "      <td>18 4 17 27 21 8 4 2 2 2 3 12 22 28 76 87 81 76...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35867</th>\n",
       "      <td>2</td>\n",
       "      <td>219 210 176 66 70 118 137 141 143 148 152 160 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35868</th>\n",
       "      <td>6</td>\n",
       "      <td>126 196 224 232 237 237 240 239 241 241 237 24...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35869</th>\n",
       "      <td>2</td>\n",
       "      <td>74 83 91 104 113 120 133 146 157 164 159 140 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35870</th>\n",
       "      <td>0</td>\n",
       "      <td>211 210 210 209 209 208 213 243 206 162 150 14...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35871</th>\n",
       "      <td>5</td>\n",
       "      <td>209 206 187 137 107 95 67 61 56 77 124 176 198...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35872</th>\n",
       "      <td>6</td>\n",
       "      <td>103 102 103 103 102 102 106 97 98 148 170 176 ...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35873</th>\n",
       "      <td>2</td>\n",
       "      <td>121 83 72 52 58 53 49 51 55 59 65 81 98 105 11...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35874</th>\n",
       "      <td>6</td>\n",
       "      <td>255 255 255 255 254 253 255 234 125 76 58 53 7...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35875</th>\n",
       "      <td>6</td>\n",
       "      <td>58 41 42 36 20 22 28 32 28 21 16 43 70 82 98 7...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35876</th>\n",
       "      <td>3</td>\n",
       "      <td>0 0 0 9 17 14 15 6 12 18 24 32 60 68 70 72 74 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35877</th>\n",
       "      <td>5</td>\n",
       "      <td>249 248 248 247 247 245 242 239 240 198 124 10...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35878</th>\n",
       "      <td>4</td>\n",
       "      <td>70 71 72 72 73 73 73 74 74 77 45 5 0 0 0 0 0 0...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35879</th>\n",
       "      <td>4</td>\n",
       "      <td>89 109 107 115 121 135 147 157 171 172 177 187...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35880</th>\n",
       "      <td>6</td>\n",
       "      <td>57 67 65 57 65 68 72 81 37 1 1 0 1 1 2 2 0 0 0...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35881</th>\n",
       "      <td>3</td>\n",
       "      <td>38 36 37 22 25 24 25 28 27 20 30 36 34 44 47 6...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>0</td>\n",
       "      <td>241 241 242 239 241 239 240 226 192 115 101 12...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35883</th>\n",
       "      <td>3</td>\n",
       "      <td>141 141 142 148 107 77 75 75 85 97 101 75 76 8...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>0</td>\n",
       "      <td>52 44 125 177 172 163 155 156 158 159 158 153 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>6</td>\n",
       "      <td>97 105 106 99 93 93 110 111 118 110 99 101 97 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>0</td>\n",
       "      <td>110 105 86 52 39 40 46 37 36 48 42 39 54 69 75...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35887 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion                                             pixels        Usage\n",
       "0            6  101 89 107 102 92 92 95 101 113 112 103 116 13...     Training\n",
       "1            2  40 35 40 65 89 110 128 137 145 153 156 158 159...     Training\n",
       "2            2  34 52 33 53 73 65 45 38 53 63 68 63 59 51 39 2...   PublicTest\n",
       "3            2  235 236 233 141 92 116 103 80 67 75 71 55 65 6...     Training\n",
       "4            4  104 74 72 74 72 70 69 69 71 69 72 70 69 72 69 ...     Training\n",
       "5            5  13 15 16 17 16 18 14 18 24 31 38 43 43 45 55 6...  PrivateTest\n",
       "6            6  83 64 60 59 60 53 45 50 54 47 40 37 44 48 48 5...     Training\n",
       "7            3  255 239 107 55 45 61 57 51 65 80 92 96 99 101 ...     Training\n",
       "8            5  202 204 201 194 212 202 128 50 19 23 20 9 8 13...     Training\n",
       "9            3  193 193 194 194 194 196 196 196 197 197 196 19...     Training\n",
       "10           6  254 254 251 255 124 0 4 29 58 102 186 194 188 ...     Training\n",
       "11           6  179 180 180 180 180 182 181 182 187 157 164 18...     Training\n",
       "12           2  216 216 215 213 212 210 207 204 204 202 201 20...     Training\n",
       "13           0  242 242 242 241 241 245 72 3 7 8 12 9 17 16 18...     Training\n",
       "14           6  119 119 119 118 83 67 66 66 67 69 72 74 73 73 ...     Training\n",
       "15           2  255 254 250 255 195 100 108 135 147 153 157 15...     Training\n",
       "16           0  30 29 33 31 31 29 25 26 26 28 30 31 35 38 43 4...  PrivateTest\n",
       "17           6  213 214 217 219 222 226 228 229 227 231 185 15...     Training\n",
       "18           3  184 191 156 198 153 160 133 155 77 93 145 149 ...     Training\n",
       "19           0  248 247 247 251 220 198 200 207 206 202 196 19...     Training\n",
       "20           4  1 3 3 3 2 36 72 58 33 53 60 66 68 71 75 75 81 ...     Training\n",
       "21           3  36 32 31 33 32 38 25 20 20 15 21 35 48 73 111 ...     Training\n",
       "22           3  16 10 24 35 60 106 147 174 186 193 198 202 208...     Training\n",
       "23           3  67 68 69 67 67 63 70 71 67 104 137 153 177 185...     Training\n",
       "24           3  155 161 163 155 145 140 133 154 158 98 49 41 3...  PrivateTest\n",
       "25           5  177 169 141 144 148 130 122 131 113 124 104 10...     Training\n",
       "26           0  32 33 33 34 30 33 45 74 90 86 89 95 95 95 105 ...     Training\n",
       "27           4  153 182 183 190 203 211 203 197 197 192 192 19...     Training\n",
       "28           2  182 64 53 65 35 31 37 46 46 51 59 64 68 79 90 ...     Training\n",
       "29           3  29 67 114 138 157 172 178 182 184 180 178 179 ...     Training\n",
       "...        ...                                                ...          ...\n",
       "35857        5  254 254 254 252 250 248 245 224 228 233 172 18...     Training\n",
       "35858        6  118 118 120 118 115 112 130 67 5 24 19 13 16 2...     Training\n",
       "35859        3  233 224 215 209 225 218 206 204 196 193 212 17...     Training\n",
       "35860        4  76 76 79 80 81 83 88 89 89 89 89 87 93 97 100 ...     Training\n",
       "35861        0  28 32 35 51 65 76 70 82 93 97 110 127 131 133 ...     Training\n",
       "35862        0  105 104 119 120 119 118 122 116 114 115 113 11...     Training\n",
       "35863        4  47 45 43 43 41 38 166 191 218 213 207 154 135 ...  PrivateTest\n",
       "35864        6  44 49 58 41 49 54 33 46 81 105 123 133 90 52 5...     Training\n",
       "35865        4  51 75 80 103 75 76 76 64 89 113 111 101 120 12...     Training\n",
       "35866        6  18 4 17 27 21 8 4 2 2 2 3 12 22 28 76 87 81 76...  PrivateTest\n",
       "35867        2  219 210 176 66 70 118 137 141 143 148 152 160 ...     Training\n",
       "35868        6  126 196 224 232 237 237 240 239 241 241 237 24...   PublicTest\n",
       "35869        2  74 83 91 104 113 120 133 146 157 164 159 140 1...     Training\n",
       "35870        0  211 210 210 209 209 208 213 243 206 162 150 14...     Training\n",
       "35871        5  209 206 187 137 107 95 67 61 56 77 124 176 198...     Training\n",
       "35872        6  103 102 103 103 102 102 106 97 98 148 170 176 ...  PrivateTest\n",
       "35873        2  121 83 72 52 58 53 49 51 55 59 65 81 98 105 11...     Training\n",
       "35874        6  255 255 255 255 254 253 255 234 125 76 58 53 7...     Training\n",
       "35875        6  58 41 42 36 20 22 28 32 28 21 16 43 70 82 98 7...     Training\n",
       "35876        3  0 0 0 9 17 14 15 6 12 18 24 32 60 68 70 72 74 ...     Training\n",
       "35877        5  249 248 248 247 247 245 242 239 240 198 124 10...     Training\n",
       "35878        4  70 71 72 72 73 73 73 74 74 77 45 5 0 0 0 0 0 0...  PrivateTest\n",
       "35879        4  89 109 107 115 121 135 147 157 171 172 177 187...     Training\n",
       "35880        6  57 67 65 57 65 68 72 81 37 1 1 0 1 1 2 2 0 0 0...     Training\n",
       "35881        3  38 36 37 22 25 24 25 28 27 20 30 36 34 44 47 6...     Training\n",
       "35882        0  241 241 242 239 241 239 240 226 192 115 101 12...  PrivateTest\n",
       "35883        3  141 141 142 148 107 77 75 75 85 97 101 75 76 8...     Training\n",
       "35884        0  52 44 125 177 172 163 155 156 158 159 158 153 ...     Training\n",
       "35885        6  97 105 106 99 93 93 110 111 118 110 99 101 97 ...     Training\n",
       "35886        0  110 105 86 52 39 40 46 37 36 48 42 39 54 69 75...  PrivateTest\n",
       "\n",
       "[35887 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify a sequence in-place by shuffling its contents. \n",
    "dataset_facial_expression = dataset_facial_expression.sample(frac=1).reset_index(drop=True)\n",
    "dataset_facial_expression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration and plot pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x180ba38b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy</td>\n",
       "      <td>8989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>6198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sad</td>\n",
       "      <td>6077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fear</td>\n",
       "      <td>5121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angry</td>\n",
       "      <td>4953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Surprise</td>\n",
       "      <td>4002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Disgust</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion  count\n",
       "3     Happy   8989\n",
       "6   Neutral   6198\n",
       "4       Sad   6077\n",
       "2      Fear   5121\n",
       "0     Angry   4953\n",
       "5  Surprise   4002\n",
       "1   Disgust    547"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delais_emotion_label = (\"Happy\" , \"Neutral\", \"Sad\", \"Fear\" , \"Angry\", \"Surprise\" ,\"Disgust\")\n",
    "delais_emotion = pd.DataFrame(data=dataset_facial_expression[\"emotion\"].value_counts())\n",
    "\n",
    "delais_emotion[\"count\"] = delais_emotion[\"emotion\"]\n",
    "delais_emotion[\"emotion\"] = delais_emotion_label\n",
    "delais_emotion\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(delais_emotion[\"emotion\"], delais_emotion[\"count\"] )\n",
    "ax.set_title(\"Data Exploration\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.set_xlabel(\"Emotions\")\n",
    "ax.grid()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "delais_emotion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((35887, 48, 48))\n",
    "#35887\n",
    "for i in range(35887):\n",
    "    imagen = dataset_facial_expression[\"pixels\"][0+i]\n",
    "    imagen_list_pixel = imagen.split(\" \")\n",
    "    imagen_array_pixel = np.asarray(imagen_list_pixel, dtype=float)\n",
    "    imagen_rezise_pixel = imagen_array_pixel.reshape(-1,48,48)    \n",
    "    image_gray = rgb2gray(imagen_rezise_pixel[0])\n",
    "    image_gray = gaussian(image_gray, 1)\n",
    "    image_eroded = image_gray-erosion(image_gray,disk(1.8))\n",
    "    imagen_array_pixel = np.asarray(image_eroded, dtype=float)\n",
    "    imagen_rezise_pixel = imagen_array_pixel.reshape(-1,48,48)   \n",
    "    y[i] = y[i]+imagen_rezise_pixel[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7177"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = y[:28709]\n",
    "train_labels = np.array(dataset_facial_expression[\"emotion\"][:28709])\n",
    "test_images = y[28710:]\n",
    "test_labels = np.array( dataset_facial_expression[\"emotion\"][28710:])\n",
    "len(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x184b42fb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0], cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709 train examples\n",
      "7177 test examples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "num_classes = 7\n",
    "epochs = 1000\n",
    "\n",
    "train_images = train_images.reshape(28709 , 2304)\n",
    "test_images = test_images.reshape(7177 , 2304)\n",
    "train_images = train_images.astype(\"float32\")\n",
    "test_images = test_images.astype(\"float32\")\n",
    "train_images /= 255\n",
    "test_images /= 255\n",
    "\n",
    "print(train_images.shape[0], \"train examples\") \n",
    "print(test_images.shape[0], \"test examples\") \n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation=\"relu\", input_shape=(2304,) ))\n",
    "model.add(Dropout(1))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(1))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 1,446,407\n",
      "Trainable params: 1,446,407\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=RMSprop(),\n",
    "             metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 7177 samples\n",
      "Epoch 1/1000\n",
      "28709/28709 [==============================] - 6s 204us/step - loss: 1.8717 - acc: 0.2432 - val_loss: 1.8484 - val_acc: 0.2448\n",
      "Epoch 2/1000\n",
      "28709/28709 [==============================] - 5s 187us/step - loss: 1.7828 - acc: 0.2751 - val_loss: 1.8647 - val_acc: 0.1909\n",
      "Epoch 3/1000\n",
      "28709/28709 [==============================] - 5s 186us/step - loss: 1.7474 - acc: 0.2959 - val_loss: 1.8871 - val_acc: 0.2037\n",
      "Epoch 4/1000\n",
      "28709/28709 [==============================] - 5s 186us/step - loss: 1.7290 - acc: 0.3046 - val_loss: 1.7461 - val_acc: 0.2927\n",
      "Epoch 5/1000\n",
      "28709/28709 [==============================] - 5s 188us/step - loss: 1.7133 - acc: 0.3142 - val_loss: 1.8409 - val_acc: 0.2367\n",
      "Epoch 6/1000\n",
      "28709/28709 [==============================] - 5s 188us/step - loss: 1.6992 - acc: 0.3220 - val_loss: 1.7921 - val_acc: 0.3001\n",
      "Epoch 7/1000\n",
      "28709/28709 [==============================] - 5s 190us/step - loss: 1.6949 - acc: 0.3288 - val_loss: 1.7943 - val_acc: 0.2451\n",
      "Epoch 8/1000\n",
      "28709/28709 [==============================] - 5s 187us/step - loss: 1.6682 - acc: 0.3388 - val_loss: 1.7664 - val_acc: 0.2874\n",
      "Epoch 9/1000\n",
      "28709/28709 [==============================] - 5s 188us/step - loss: 1.6564 - acc: 0.3425 - val_loss: 1.8345 - val_acc: 0.2437\n",
      "Epoch 10/1000\n",
      "28709/28709 [==============================] - 5s 188us/step - loss: 1.6460 - acc: 0.3495 - val_loss: 1.8596 - val_acc: 0.2434\n",
      "Epoch 11/1000\n",
      "28709/28709 [==============================] - 5s 186us/step - loss: 1.6363 - acc: 0.3577 - val_loss: 1.8190 - val_acc: 0.3455\n",
      "Epoch 12/1000\n",
      "28709/28709 [==============================] - 5s 186us/step - loss: 1.6173 - acc: 0.3681 - val_loss: 1.7003 - val_acc: 0.3209\n",
      "Epoch 13/1000\n",
      "28709/28709 [==============================] - 5s 191us/step - loss: 1.6068 - acc: 0.3675 - val_loss: 1.9014 - val_acc: 0.2913\n",
      "Epoch 14/1000\n",
      "28709/28709 [==============================] - 8s 282us/step - loss: 1.5919 - acc: 0.3760 - val_loss: 1.7164 - val_acc: 0.3539\n",
      "Epoch 15/1000\n",
      "28709/28709 [==============================] - 6s 217us/step - loss: 1.5651 - acc: 0.3866 - val_loss: 1.7335 - val_acc: 0.2936\n",
      "Epoch 16/1000\n",
      "28709/28709 [==============================] - 8s 284us/step - loss: 1.5636 - acc: 0.3902 - val_loss: 1.9372 - val_acc: 0.2877\n",
      "Epoch 17/1000\n",
      "28709/28709 [==============================] - 8s 266us/step - loss: 1.5340 - acc: 0.4012 - val_loss: 1.8971 - val_acc: 0.2483\n",
      "Epoch 18/1000\n",
      "28709/28709 [==============================] - 10s 357us/step - loss: 1.5282 - acc: 0.4104 - val_loss: 1.7664 - val_acc: 0.3145\n",
      "Epoch 19/1000\n",
      "28709/28709 [==============================] - 5s 187us/step - loss: 1.5010 - acc: 0.4198 - val_loss: 1.7420 - val_acc: 0.3280\n",
      "Epoch 20/1000\n",
      "28709/28709 [==============================] - 10s 352us/step - loss: 1.4838 - acc: 0.4304 - val_loss: 1.7132 - val_acc: 0.3329\n",
      "Epoch 21/1000\n",
      "28709/28709 [==============================] - 5s 188us/step - loss: 1.4732 - acc: 0.4334 - val_loss: 1.7429 - val_acc: 0.3613\n",
      "Epoch 22/1000\n",
      "28709/28709 [==============================] - 11s 373us/step - loss: 1.4461 - acc: 0.4511 - val_loss: 1.7385 - val_acc: 0.3504\n",
      "Epoch 23/1000\n",
      "28709/28709 [==============================] - 9s 307us/step - loss: 1.4252 - acc: 0.4548 - val_loss: 1.8959 - val_acc: 0.3109\n",
      "Epoch 24/1000\n",
      "28709/28709 [==============================] - 7s 257us/step - loss: 1.4056 - acc: 0.4639 - val_loss: 1.8247 - val_acc: 0.3044\n",
      "Epoch 25/1000\n",
      "28709/28709 [==============================] - 12s 407us/step - loss: 1.4090 - acc: 0.4633 - val_loss: 1.7528 - val_acc: 0.3529\n",
      "Epoch 26/1000\n",
      "28709/28709 [==============================] - 9s 311us/step - loss: 1.3757 - acc: 0.4779 - val_loss: 1.7848 - val_acc: 0.3574\n",
      "Epoch 27/1000\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.3462 - acc: 0.4870 - val_loss: 1.7671 - val_acc: 0.3564\n",
      "Epoch 28/1000\n",
      "28709/28709 [==============================] - 11s 390us/step - loss: 1.3395 - acc: 0.4912 - val_loss: 1.8275 - val_acc: 0.3357\n",
      "Epoch 29/1000\n",
      "28709/28709 [==============================] - 8s 267us/step - loss: 1.3266 - acc: 0.5012 - val_loss: 2.2547 - val_acc: 0.3287\n",
      "Epoch 30/1000\n",
      "28709/28709 [==============================] - 10s 338us/step - loss: 1.3120 - acc: 0.5084 - val_loss: 2.0221 - val_acc: 0.3366\n",
      "Epoch 31/1000\n",
      "28709/28709 [==============================] - 12s 430us/step - loss: 1.2925 - acc: 0.5150 - val_loss: 1.7864 - val_acc: 0.3546\n",
      "Epoch 32/1000\n",
      "28709/28709 [==============================] - 8s 266us/step - loss: 1.2678 - acc: 0.5234 - val_loss: 1.7157 - val_acc: 0.3736\n",
      "Epoch 33/1000\n",
      "28709/28709 [==============================] - 10s 351us/step - loss: 1.2436 - acc: 0.5301 - val_loss: 1.7673 - val_acc: 0.3730\n",
      "Epoch 34/1000\n",
      "28709/28709 [==============================] - 12s 411us/step - loss: 1.2238 - acc: 0.5440 - val_loss: 1.8785 - val_acc: 0.3405\n",
      "Epoch 35/1000\n",
      "28709/28709 [==============================] - 10s 343us/step - loss: 1.2016 - acc: 0.5523 - val_loss: 1.8328 - val_acc: 0.3394\n",
      "Epoch 36/1000\n",
      "28709/28709 [==============================] - 8s 265us/step - loss: 1.1842 - acc: 0.5621 - val_loss: 1.8889 - val_acc: 0.3398\n",
      "Epoch 37/1000\n",
      "28709/28709 [==============================] - 12s 413us/step - loss: 1.1959 - acc: 0.5578 - val_loss: 1.8611 - val_acc: 0.3464\n",
      "Epoch 38/1000\n",
      "28709/28709 [==============================] - 7s 244us/step - loss: 1.1558 - acc: 0.5712 - val_loss: 1.9518 - val_acc: 0.3631\n",
      "Epoch 39/1000\n",
      "28709/28709 [==============================] - 10s 356us/step - loss: 1.1530 - acc: 0.5781 - val_loss: 2.1293 - val_acc: 0.3035\n",
      "Epoch 40/1000\n",
      "28709/28709 [==============================] - 12s 407us/step - loss: 1.1314 - acc: 0.5821 - val_loss: 2.1902 - val_acc: 0.3534\n",
      "Epoch 41/1000\n",
      "28709/28709 [==============================] - 6s 202us/step - loss: 1.1272 - acc: 0.5835 - val_loss: 1.9492 - val_acc: 0.3560\n",
      "Epoch 42/1000\n",
      "28709/28709 [==============================] - 11s 397us/step - loss: 1.0876 - acc: 0.6000 - val_loss: 2.3007 - val_acc: 0.2557\n",
      "Epoch 43/1000\n",
      "28709/28709 [==============================] - 10s 352us/step - loss: 1.0892 - acc: 0.6010 - val_loss: 2.1127 - val_acc: 0.3083\n",
      "Epoch 44/1000\n",
      "28709/28709 [==============================] - 7s 239us/step - loss: 1.0693 - acc: 0.6071 - val_loss: 2.0670 - val_acc: 0.3681\n",
      "Epoch 45/1000\n",
      "28709/28709 [==============================] - 12s 406us/step - loss: 1.0459 - acc: 0.6141 - val_loss: 1.9811 - val_acc: 0.3496\n",
      "Epoch 46/1000\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 1.0391 - acc: 0.6178 - val_loss: 2.0605 - val_acc: 0.3326\n",
      "Epoch 47/1000\n",
      "28709/28709 [==============================] - 8s 290us/step - loss: 1.0069 - acc: 0.6310 - val_loss: 1.9634 - val_acc: 0.3651\n",
      "Epoch 48/1000\n",
      "28709/28709 [==============================] - 12s 414us/step - loss: 1.0090 - acc: 0.6295 - val_loss: 2.5140 - val_acc: 0.2702\n",
      "Epoch 49/1000\n",
      "28709/28709 [==============================] - 8s 293us/step - loss: 0.9801 - acc: 0.6415 - val_loss: 1.9772 - val_acc: 0.3858\n",
      "Epoch 50/1000\n",
      "28709/28709 [==============================] - 9s 296us/step - loss: 0.9682 - acc: 0.6436 - val_loss: 2.2032 - val_acc: 0.3614\n",
      "Epoch 51/1000\n",
      "28709/28709 [==============================] - 12s 427us/step - loss: 0.9482 - acc: 0.6520 - val_loss: 2.0039 - val_acc: 0.3617\n",
      "Epoch 52/1000\n",
      "28709/28709 [==============================] - 6s 217us/step - loss: 0.9200 - acc: 0.6574 - val_loss: 1.9210 - val_acc: 0.3567\n",
      "Epoch 53/1000\n",
      "28709/28709 [==============================] - 11s 383us/step - loss: 0.9185 - acc: 0.6611 - val_loss: 2.0975 - val_acc: 0.3157\n",
      "Epoch 54/1000\n",
      "28709/28709 [==============================] - 11s 394us/step - loss: 0.8872 - acc: 0.6730 - val_loss: 2.0770 - val_acc: 0.3614\n",
      "Epoch 55/1000\n",
      "28709/28709 [==============================] - 6s 212us/step - loss: 0.9058 - acc: 0.6730 - val_loss: 2.0838 - val_acc: 0.3595\n",
      "Epoch 56/1000\n",
      "28709/28709 [==============================] - 12s 427us/step - loss: 0.8755 - acc: 0.6821 - val_loss: 2.0829 - val_acc: 0.3593\n",
      "Epoch 57/1000\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.8511 - acc: 0.6855 - val_loss: 2.2225 - val_acc: 0.3252\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 9s 314us/step - loss: 0.8424 - acc: 0.6929 - val_loss: 2.4886 - val_acc: 0.3329\n",
      "Epoch 59/1000\n",
      "28709/28709 [==============================] - 12s 409us/step - loss: 0.8278 - acc: 0.7001 - val_loss: 2.6405 - val_acc: 0.3298\n",
      "Epoch 60/1000\n",
      "28709/28709 [==============================] - 7s 238us/step - loss: 0.8446 - acc: 0.6956 - val_loss: 2.2511 - val_acc: 0.3582\n",
      "Epoch 61/1000\n",
      "28709/28709 [==============================] - 10s 357us/step - loss: 0.8228 - acc: 0.7028 - val_loss: 2.2296 - val_acc: 0.3814\n",
      "Epoch 62/1000\n",
      "28709/28709 [==============================] - 12s 403us/step - loss: 0.7924 - acc: 0.7084 - val_loss: 2.1651 - val_acc: 0.3443\n",
      "Epoch 63/1000\n",
      "28709/28709 [==============================] - 6s 205us/step - loss: 0.7683 - acc: 0.7171 - val_loss: 2.2413 - val_acc: 0.3577\n",
      "Epoch 64/1000\n",
      "28709/28709 [==============================] - 12s 407us/step - loss: 0.7973 - acc: 0.7193 - val_loss: 2.5073 - val_acc: 0.3761\n",
      "Epoch 65/1000\n",
      "28709/28709 [==============================] - 10s 354us/step - loss: 0.7550 - acc: 0.7276 - val_loss: 2.5977 - val_acc: 0.3290\n",
      "Epoch 66/1000\n",
      "28709/28709 [==============================] - 7s 260us/step - loss: 0.7553 - acc: 0.7260 - val_loss: 2.4788 - val_acc: 0.3684\n",
      "Epoch 67/1000\n",
      "28709/28709 [==============================] - 12s 426us/step - loss: 0.7248 - acc: 0.7407 - val_loss: 2.3735 - val_acc: 0.3352\n",
      "Epoch 68/1000\n",
      "28709/28709 [==============================] - 8s 296us/step - loss: 0.7210 - acc: 0.7416 - val_loss: 2.1070 - val_acc: 0.3931\n",
      "Epoch 69/1000\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 0.7119 - acc: 0.7418 - val_loss: 2.3200 - val_acc: 0.3776\n",
      "Epoch 70/1000\n",
      "28709/28709 [==============================] - 12s 424us/step - loss: 0.6812 - acc: 0.7544 - val_loss: 2.3148 - val_acc: 0.3947\n",
      "Epoch 71/1000\n",
      "28709/28709 [==============================] - 7s 227us/step - loss: 0.7062 - acc: 0.7540 - val_loss: 2.2062 - val_acc: 0.3756\n",
      "Epoch 72/1000\n",
      "28709/28709 [==============================] - 11s 371us/step - loss: 0.6607 - acc: 0.7619 - val_loss: 2.4479 - val_acc: 0.3766\n",
      "Epoch 73/1000\n",
      "28709/28709 [==============================] - 11s 392us/step - loss: 0.6473 - acc: 0.7698 - val_loss: 2.5507 - val_acc: 0.3660\n",
      "Epoch 74/1000\n",
      "28709/28709 [==============================] - 6s 219us/step - loss: 0.6529 - acc: 0.7775 - val_loss: 2.4860 - val_acc: 0.3591\n",
      "Epoch 75/1000\n",
      "28709/28709 [==============================] - 13s 442us/step - loss: 0.6520 - acc: 0.7674 - val_loss: 2.4706 - val_acc: 0.3908\n",
      "Epoch 76/1000\n",
      "28709/28709 [==============================] - 12s 423us/step - loss: 0.6227 - acc: 0.7746 - val_loss: 2.5037 - val_acc: 0.3574\n",
      "Epoch 77/1000\n",
      "28709/28709 [==============================] - 9s 329us/step - loss: 0.6003 - acc: 0.7838 - val_loss: 2.7297 - val_acc: 0.3532\n",
      "Epoch 78/1000\n",
      "28709/28709 [==============================] - 11s 396us/step - loss: 0.6453 - acc: 0.7808 - val_loss: 2.6504 - val_acc: 0.3802\n",
      "Epoch 79/1000\n",
      "28709/28709 [==============================] - 13s 455us/step - loss: 0.5750 - acc: 0.7947 - val_loss: 2.7722 - val_acc: 0.3592\n",
      "Epoch 80/1000\n",
      "28709/28709 [==============================] - 11s 372us/step - loss: 0.6233 - acc: 0.7795 - val_loss: 2.4159 - val_acc: 0.3974\n",
      "Epoch 81/1000\n",
      "28709/28709 [==============================] - 9s 308us/step - loss: 0.5583 - acc: 0.8027 - val_loss: 2.6308 - val_acc: 0.3607\n",
      "Epoch 82/1000\n",
      "28709/28709 [==============================] - 14s 490us/step - loss: 0.5456 - acc: 0.8092 - val_loss: 2.6482 - val_acc: 0.3600\n",
      "Epoch 83/1000\n",
      "28709/28709 [==============================] - 15s 519us/step - loss: 0.5793 - acc: 0.7944 - val_loss: 3.1115 - val_acc: 0.3132\n",
      "Epoch 84/1000\n",
      "28709/28709 [==============================] - 13s 437us/step - loss: 0.5268 - acc: 0.8214 - val_loss: 2.9344 - val_acc: 0.3609\n",
      "Epoch 85/1000\n",
      "28709/28709 [==============================] - 10s 333us/step - loss: 0.5943 - acc: 0.8038 - val_loss: 3.0800 - val_acc: 0.3453\n",
      "Epoch 86/1000\n",
      "28709/28709 [==============================] - 11s 390us/step - loss: 0.5208 - acc: 0.8218 - val_loss: 2.7470 - val_acc: 0.3460\n",
      "Epoch 87/1000\n",
      "28709/28709 [==============================] - 13s 456us/step - loss: 0.5037 - acc: 0.8242 - val_loss: 3.3760 - val_acc: 0.3687\n",
      "Epoch 88/1000\n",
      "28709/28709 [==============================] - 8s 274us/step - loss: 0.5291 - acc: 0.8334 - val_loss: 3.5818 - val_acc: 0.3458\n",
      "Epoch 89/1000\n",
      "28709/28709 [==============================] - 12s 424us/step - loss: 0.5442 - acc: 0.8270 - val_loss: 3.2020 - val_acc: 0.3568\n",
      "Epoch 90/1000\n",
      "28709/28709 [==============================] - 14s 496us/step - loss: 0.5029 - acc: 0.8470 - val_loss: 3.0583 - val_acc: 0.3408\n",
      "Epoch 91/1000\n",
      "28709/28709 [==============================] - 10s 350us/step - loss: 0.5140 - acc: 0.8242 - val_loss: 2.7605 - val_acc: 0.3762\n",
      "Epoch 92/1000\n",
      "28709/28709 [==============================] - 9s 329us/step - loss: 0.5057 - acc: 0.8275 - val_loss: 2.7315 - val_acc: 0.3979\n",
      "Epoch 93/1000\n",
      "28709/28709 [==============================] - 13s 448us/step - loss: 0.4736 - acc: 0.8355 - val_loss: 2.7605 - val_acc: 0.3623\n",
      "Epoch 94/1000\n",
      "28709/28709 [==============================] - 9s 317us/step - loss: 0.4719 - acc: 0.8391 - val_loss: 2.9605 - val_acc: 0.3964\n",
      "Epoch 95/1000\n",
      "28709/28709 [==============================] - 10s 341us/step - loss: 0.4327 - acc: 0.8583 - val_loss: 3.3846 - val_acc: 0.3812\n",
      "Epoch 96/1000\n",
      "28709/28709 [==============================] - 13s 462us/step - loss: 0.4833 - acc: 0.8538 - val_loss: 3.0838 - val_acc: 0.3922\n",
      "Epoch 97/1000\n",
      "28709/28709 [==============================] - 10s 361us/step - loss: 0.5278 - acc: 0.8391 - val_loss: 2.6403 - val_acc: 0.3991\n",
      "Epoch 98/1000\n",
      "28709/28709 [==============================] - 8s 289us/step - loss: 0.4649 - acc: 0.8643 - val_loss: 2.6396 - val_acc: 0.3809\n",
      "Epoch 99/1000\n",
      "28709/28709 [==============================] - 14s 477us/step - loss: 0.4171 - acc: 0.8611 - val_loss: 3.0466 - val_acc: 0.3690\n",
      "Epoch 100/1000\n",
      "28709/28709 [==============================] - 11s 368us/step - loss: 0.6073 - acc: 0.8247 - val_loss: 2.9174 - val_acc: 0.3816\n",
      "Epoch 101/1000\n",
      "28709/28709 [==============================] - 8s 296us/step - loss: 0.3081 - acc: 0.9047 - val_loss: 3.2060 - val_acc: 0.3886\n",
      "Epoch 102/1000\n",
      "28709/28709 [==============================] - 13s 449us/step - loss: 0.5282 - acc: 0.8490 - val_loss: 3.3425 - val_acc: 0.3444\n",
      "Epoch 103/1000\n",
      "28709/28709 [==============================] - 12s 409us/step - loss: 0.3820 - acc: 0.8859 - val_loss: 3.7014 - val_acc: 0.3748\n",
      "Epoch 104/1000\n",
      "28709/28709 [==============================] - 8s 284us/step - loss: 0.5041 - acc: 0.8546 - val_loss: 2.7969 - val_acc: 0.4056\n",
      "Epoch 105/1000\n",
      "28709/28709 [==============================] - 14s 476us/step - loss: 0.3853 - acc: 0.8949 - val_loss: 3.1856 - val_acc: 0.3687\n",
      "Epoch 106/1000\n",
      "28709/28709 [==============================] - 14s 472us/step - loss: 0.6989 - acc: 0.8233 - val_loss: 2.7304 - val_acc: 0.3886\n",
      "Epoch 107/1000\n",
      "28709/28709 [==============================] - 8s 262us/step - loss: 0.2670 - acc: 0.9293 - val_loss: 2.9971 - val_acc: 0.3989\n",
      "Epoch 108/1000\n",
      "28709/28709 [==============================] - 12s 434us/step - loss: 0.5742 - acc: 0.8538 - val_loss: 2.9991 - val_acc: 0.3607\n",
      "Epoch 109/1000\n",
      "28709/28709 [==============================] - 14s 473us/step - loss: 0.2882 - acc: 0.9143 - val_loss: 3.3181 - val_acc: 0.3549\n",
      "Epoch 110/1000\n",
      "28709/28709 [==============================] - 8s 272us/step - loss: 0.6385 - acc: 0.8389 - val_loss: 2.8371 - val_acc: 0.3991\n",
      "Epoch 111/1000\n",
      "28709/28709 [==============================] - 12s 429us/step - loss: 0.3481 - acc: 0.9148 - val_loss: 3.0215 - val_acc: 0.4173\n",
      "Epoch 112/1000\n",
      "28709/28709 [==============================] - 15s 520us/step - loss: 0.4999 - acc: 0.8674 - val_loss: 2.7765 - val_acc: 0.3942\n",
      "Epoch 113/1000\n",
      "28709/28709 [==============================] - 9s 317us/step - loss: 0.5180 - acc: 0.8804 - val_loss: 2.8024 - val_acc: 0.4023\n",
      "Epoch 114/1000\n",
      "28709/28709 [==============================] - 11s 373us/step - loss: 0.3544 - acc: 0.9045 - val_loss: 3.1727 - val_acc: 0.3982\n",
      "Epoch 115/1000\n",
      "28709/28709 [==============================] - 14s 495us/step - loss: 0.5024 - acc: 0.8737 - val_loss: 2.8268 - val_acc: 0.4094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/1000\n",
      "28709/28709 [==============================] - 9s 322us/step - loss: 0.3607 - acc: 0.9056 - val_loss: 3.1450 - val_acc: 0.3887\n",
      "Epoch 117/1000\n",
      "28709/28709 [==============================] - 10s 354us/step - loss: 0.5188 - acc: 0.8650 - val_loss: 2.8156 - val_acc: 0.4050\n",
      "Epoch 118/1000\n",
      "28709/28709 [==============================] - 15s 508us/step - loss: 0.4550 - acc: 0.8961 - val_loss: 2.9666 - val_acc: 0.3906\n",
      "Epoch 119/1000\n",
      "28709/28709 [==============================] - 8s 290us/step - loss: 0.6697 - acc: 0.8781 - val_loss: 2.9369 - val_acc: 0.3968\n",
      "Epoch 120/1000\n",
      "28709/28709 [==============================] - 11s 376us/step - loss: 0.3416 - acc: 0.9230 - val_loss: 2.9186 - val_acc: 0.3997\n",
      "Epoch 121/1000\n",
      "28709/28709 [==============================] - 13s 468us/step - loss: 0.3975 - acc: 0.9036 - val_loss: 3.2991 - val_acc: 0.4050\n",
      "Epoch 122/1000\n",
      "28709/28709 [==============================] - 9s 325us/step - loss: 0.4909 - acc: 0.8977 - val_loss: 3.2838 - val_acc: 0.4037\n",
      "Epoch 123/1000\n",
      "28709/28709 [==============================] - 10s 350us/step - loss: 0.5648 - acc: 0.8865 - val_loss: 2.9154 - val_acc: 0.3807\n",
      "Epoch 124/1000\n",
      "28709/28709 [==============================] - 13s 470us/step - loss: 0.4785 - acc: 0.9121 - val_loss: 2.8325 - val_acc: 0.3464\n",
      "Epoch 125/1000\n",
      "28709/28709 [==============================] - 10s 338us/step - loss: 0.1667 - acc: 0.9560 - val_loss: 3.8445 - val_acc: 0.3518\n",
      "Epoch 126/1000\n",
      "28709/28709 [==============================] - 9s 321us/step - loss: 0.3958 - acc: 0.9021 - val_loss: 4.7536 - val_acc: 0.3836\n",
      "Epoch 127/1000\n",
      "28709/28709 [==============================] - 14s 472us/step - loss: 0.6368 - acc: 0.8746 - val_loss: 3.5131 - val_acc: 0.4067\n",
      "Epoch 128/1000\n",
      "28709/28709 [==============================] - 10s 346us/step - loss: 0.2789 - acc: 0.9258 - val_loss: 6.3866 - val_acc: 0.3287\n",
      "Epoch 129/1000\n",
      "28709/28709 [==============================] - 9s 313us/step - loss: 0.5683 - acc: 0.8897 - val_loss: 3.7780 - val_acc: 0.4039\n",
      "Epoch 130/1000\n",
      "28709/28709 [==============================] - 14s 496us/step - loss: 0.5302 - acc: 0.8898 - val_loss: 3.7757 - val_acc: 0.4085\n",
      "Epoch 131/1000\n",
      "28709/28709 [==============================] - 12s 409us/step - loss: 0.2433 - acc: 0.9310 - val_loss: 5.8105 - val_acc: 0.2738\n",
      "Epoch 132/1000\n",
      "28709/28709 [==============================] - 8s 284us/step - loss: 0.4317 - acc: 0.9145 - val_loss: 3.8133 - val_acc: 0.3932\n",
      "Epoch 133/1000\n",
      "28709/28709 [==============================] - 14s 504us/step - loss: 0.6200 - acc: 0.8933 - val_loss: 3.7408 - val_acc: 0.4074\n",
      "Epoch 134/1000\n",
      "28709/28709 [==============================] - 10s 351us/step - loss: 0.2462 - acc: 0.9359 - val_loss: 4.1693 - val_acc: 0.4046\n",
      "Epoch 135/1000\n",
      "28709/28709 [==============================] - 10s 355us/step - loss: 0.7945 - acc: 0.8705 - val_loss: 3.8473 - val_acc: 0.4028\n",
      "Epoch 136/1000\n",
      "28709/28709 [==============================] - 13s 459us/step - loss: 0.4180 - acc: 0.9270 - val_loss: 5.0405 - val_acc: 0.3262\n",
      "Epoch 137/1000\n",
      "28709/28709 [==============================] - 11s 372us/step - loss: 0.7064 - acc: 0.8773 - val_loss: 4.0330 - val_acc: 0.3836\n",
      "Epoch 138/1000\n",
      "28709/28709 [==============================] - 9s 327us/step - loss: 0.2671 - acc: 0.9308 - val_loss: 6.3897 - val_acc: 0.3457\n",
      "Epoch 139/1000\n",
      "28709/28709 [==============================] - 13s 459us/step - loss: 0.5364 - acc: 0.9023 - val_loss: 3.9702 - val_acc: 0.3854\n",
      "Epoch 140/1000\n",
      "28709/28709 [==============================] - 13s 440us/step - loss: 0.6602 - acc: 0.8804 - val_loss: 3.7772 - val_acc: 0.3997\n",
      "Epoch 141/1000\n",
      "28709/28709 [==============================] - 8s 270us/step - loss: 0.3390 - acc: 0.9280 - val_loss: 3.9667 - val_acc: 0.4050\n",
      "Epoch 142/1000\n",
      "28709/28709 [==============================] - 13s 464us/step - loss: 0.4609 - acc: 0.9095 - val_loss: 3.8057 - val_acc: 0.4060\n",
      "Epoch 143/1000\n",
      "28709/28709 [==============================] - 11s 399us/step - loss: 0.5419 - acc: 0.9012 - val_loss: 4.1455 - val_acc: 0.3890\n",
      "Epoch 144/1000\n",
      "28709/28709 [==============================] - 8s 263us/step - loss: 0.2025 - acc: 0.9472 - val_loss: 4.3953 - val_acc: 0.3531\n",
      "Epoch 145/1000\n",
      "28709/28709 [==============================] - 14s 472us/step - loss: 0.5520 - acc: 0.9021 - val_loss: 4.1075 - val_acc: 0.3935\n",
      "Epoch 146/1000\n",
      "28709/28709 [==============================] - 11s 374us/step - loss: 0.4572 - acc: 0.9126 - val_loss: 4.1546 - val_acc: 0.4052\n",
      "Epoch 147/1000\n",
      "28709/28709 [==============================] - 8s 293us/step - loss: 0.6958 - acc: 0.8941 - val_loss: 3.9164 - val_acc: 0.4052\n",
      "Epoch 148/1000\n",
      "28709/28709 [==============================] - 14s 478us/step - loss: 0.3532 - acc: 0.9274 - val_loss: 4.4756 - val_acc: 0.4115\n",
      "Epoch 149/1000\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.9760 - acc: 0.8398 - val_loss: 4.0907 - val_acc: 0.3960\n",
      "Epoch 150/1000\n",
      "28709/28709 [==============================] - 11s 372us/step - loss: 0.2544 - acc: 0.9344 - val_loss: 4.2690 - val_acc: 0.4034\n",
      "Epoch 151/1000\n",
      "28709/28709 [==============================] - 13s 464us/step - loss: 0.5531 - acc: 0.8975 - val_loss: 3.8572 - val_acc: 0.4025\n",
      "Epoch 152/1000\n",
      "28709/28709 [==============================] - 8s 287us/step - loss: 0.4689 - acc: 0.9082 - val_loss: 4.2175 - val_acc: 0.4032\n",
      "Epoch 153/1000\n",
      "28709/28709 [==============================] - 11s 372us/step - loss: 0.6087 - acc: 0.9022 - val_loss: 3.8944 - val_acc: 0.3871\n",
      "Epoch 154/1000\n",
      "28709/28709 [==============================] - 13s 463us/step - loss: 0.2315 - acc: 0.9469 - val_loss: 4.4711 - val_acc: 0.3900\n",
      "Epoch 155/1000\n",
      "28709/28709 [==============================] - 7s 230us/step - loss: 0.5937 - acc: 0.8979 - val_loss: 3.9603 - val_acc: 0.4046\n",
      "Epoch 156/1000\n",
      "28709/28709 [==============================] - 12s 429us/step - loss: 0.3417 - acc: 0.9187 - val_loss: 3.8717 - val_acc: 0.4071\n",
      "Epoch 157/1000\n",
      "28709/28709 [==============================] - 11s 384us/step - loss: 1.0011 - acc: 0.8694 - val_loss: 4.0397 - val_acc: 0.3929\n",
      "Epoch 158/1000\n",
      "28709/28709 [==============================] - 8s 274us/step - loss: 0.5273 - acc: 0.9189 - val_loss: 2.9686 - val_acc: 0.3493\n",
      "Epoch 159/1000\n",
      "28709/28709 [==============================] - 13s 458us/step - loss: 0.1056 - acc: 0.9747 - val_loss: 4.5681 - val_acc: 0.4059\n",
      "Epoch 160/1000\n",
      "28709/28709 [==============================] - 10s 341us/step - loss: 0.8425 - acc: 0.8836 - val_loss: 3.9378 - val_acc: 0.4059\n",
      "Epoch 161/1000\n",
      "28709/28709 [==============================] - 9s 328us/step - loss: 0.6327 - acc: 0.8807 - val_loss: 3.5116 - val_acc: 0.3938\n",
      "Epoch 162/1000\n",
      "28709/28709 [==============================] - 14s 488us/step - loss: 1.1206 - acc: 0.8598 - val_loss: 2.9072 - val_acc: 0.4000\n",
      "Epoch 163/1000\n",
      "28709/28709 [==============================] - 9s 312us/step - loss: 0.0686 - acc: 0.9869 - val_loss: 5.3145 - val_acc: 0.3979\n",
      "Epoch 164/1000\n",
      "28709/28709 [==============================] - 10s 343us/step - loss: 0.6846 - acc: 0.8962 - val_loss: 4.1545 - val_acc: 0.3867\n",
      "Epoch 165/1000\n",
      "28709/28709 [==============================] - 13s 458us/step - loss: 0.6587 - acc: 0.8819 - val_loss: 4.0133 - val_acc: 0.4011\n",
      "Epoch 166/1000\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 1.1465 - acc: 0.8464 - val_loss: 3.8862 - val_acc: 0.3995\n",
      "Epoch 167/1000\n",
      "28709/28709 [==============================] - 11s 385us/step - loss: 0.2008 - acc: 0.9698 - val_loss: 5.4458 - val_acc: 0.3042\n",
      "Epoch 168/1000\n",
      "28709/28709 [==============================] - 13s 465us/step - loss: 0.2683 - acc: 0.9417 - val_loss: 4.6696 - val_acc: 0.3968\n",
      "Epoch 169/1000\n",
      "28709/28709 [==============================] - 7s 246us/step - loss: 0.7141 - acc: 0.8933 - val_loss: 4.2682 - val_acc: 0.4052\n",
      "Epoch 170/1000\n",
      "28709/28709 [==============================] - 11s 400us/step - loss: 0.2629 - acc: 0.9393 - val_loss: 4.4282 - val_acc: 0.3982\n",
      "Epoch 171/1000\n",
      "28709/28709 [==============================] - 11s 381us/step - loss: 0.8508 - acc: 0.8782 - val_loss: 3.8353 - val_acc: 0.3997\n",
      "Epoch 172/1000\n",
      "28709/28709 [==============================] - 8s 277us/step - loss: 0.8567 - acc: 0.8839 - val_loss: 3.2730 - val_acc: 0.3996\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 13s 464us/step - loss: 0.6128 - acc: 0.9266 - val_loss: 4.5633 - val_acc: 0.2721\n",
      "Epoch 174/1000\n",
      "28709/28709 [==============================] - 10s 348us/step - loss: 0.1557 - acc: 0.9638 - val_loss: 4.4712 - val_acc: 0.4011\n",
      "Epoch 175/1000\n",
      "28709/28709 [==============================] - 9s 320us/step - loss: 0.2423 - acc: 0.9418 - val_loss: 4.9104 - val_acc: 0.3999\n",
      "Epoch 176/1000\n",
      "28709/28709 [==============================] - 13s 454us/step - loss: 1.0400 - acc: 0.8631 - val_loss: 4.5366 - val_acc: 0.4081\n",
      "Epoch 177/1000\n",
      "28709/28709 [==============================] - 9s 312us/step - loss: 1.3944 - acc: 0.8547 - val_loss: 3.5927 - val_acc: 0.4049\n",
      "Epoch 178/1000\n",
      "28709/28709 [==============================] - 10s 344us/step - loss: 0.6226 - acc: 0.9048 - val_loss: 3.3436 - val_acc: 0.3627\n",
      "Epoch 179/1000\n",
      "28709/28709 [==============================] - 13s 454us/step - loss: 0.0799 - acc: 0.9837 - val_loss: 4.3218 - val_acc: 0.4074\n",
      "Epoch 180/1000\n",
      "28709/28709 [==============================] - 6s 218us/step - loss: 0.8891 - acc: 0.8830 - val_loss: 3.9818 - val_acc: 0.3890\n",
      "Epoch 181/1000\n",
      "28709/28709 [==============================] - 14s 481us/step - loss: 0.2309 - acc: 0.9596 - val_loss: 10.2364 - val_acc: 0.2286\n",
      "Epoch 182/1000\n",
      "28709/28709 [==============================] - 14s 488us/step - loss: 0.7793 - acc: 0.9014 - val_loss: 4.7058 - val_acc: 0.4077\n",
      "Epoch 183/1000\n",
      "28709/28709 [==============================] - 9s 325us/step - loss: 1.0004 - acc: 0.8661 - val_loss: 3.7470 - val_acc: 0.4088\n",
      "Epoch 184/1000\n",
      "28709/28709 [==============================] - 9s 329us/step - loss: 0.8737 - acc: 0.8902 - val_loss: 3.3212 - val_acc: 0.3956\n",
      "Epoch 185/1000\n",
      "28709/28709 [==============================] - 13s 469us/step - loss: 0.4954 - acc: 0.9395 - val_loss: 5.9637 - val_acc: 0.2270\n",
      "Epoch 186/1000\n",
      "28709/28709 [==============================] - 10s 361us/step - loss: 0.3800 - acc: 0.9245 - val_loss: 4.7520 - val_acc: 0.3939\n",
      "Epoch 187/1000\n",
      "28709/28709 [==============================] - 9s 314us/step - loss: 0.6223 - acc: 0.9019 - val_loss: 4.5208 - val_acc: 0.3965\n",
      "Epoch 188/1000\n",
      "28709/28709 [==============================] - 13s 456us/step - loss: 0.9886 - acc: 0.8777 - val_loss: 3.5301 - val_acc: 0.3935\n",
      "Epoch 189/1000\n",
      "28709/28709 [==============================] - 9s 312us/step - loss: 0.0361 - acc: 0.9947 - val_loss: 4.6497 - val_acc: 0.4064\n",
      "Epoch 190/1000\n",
      "28709/28709 [==============================] - 10s 336us/step - loss: 1.1976 - acc: 0.8747 - val_loss: 4.0686 - val_acc: 0.4084\n",
      "Epoch 191/1000\n",
      "28709/28709 [==============================] - 13s 470us/step - loss: 0.7536 - acc: 0.8858 - val_loss: 3.5682 - val_acc: 0.3943\n",
      "Epoch 192/1000\n",
      "28709/28709 [==============================] - 8s 264us/step - loss: 0.0361 - acc: 0.9946 - val_loss: 5.1613 - val_acc: 0.3932\n",
      "Epoch 193/1000\n",
      "28709/28709 [==============================] - 11s 382us/step - loss: 0.7947 - acc: 0.8860 - val_loss: 4.4520 - val_acc: 0.3979\n",
      "Epoch 194/1000\n",
      "28709/28709 [==============================] - 13s 446us/step - loss: 0.7256 - acc: 0.8988 - val_loss: 4.8571 - val_acc: 0.4030\n",
      "Epoch 195/1000\n",
      "28709/28709 [==============================] - 6s 226us/step - loss: 1.1928 - acc: 0.8622 - val_loss: 3.5065 - val_acc: 0.3975\n",
      "Epoch 196/1000\n",
      "28709/28709 [==============================] - 13s 440us/step - loss: 0.0513 - acc: 0.9900 - val_loss: 4.8776 - val_acc: 0.3138\n",
      "Epoch 197/1000\n",
      "28709/28709 [==============================] - 11s 374us/step - loss: 0.2435 - acc: 0.9421 - val_loss: 4.4802 - val_acc: 0.3823\n",
      "Epoch 198/1000\n",
      "28709/28709 [==============================] - 8s 292us/step - loss: 0.5526 - acc: 0.9029 - val_loss: 4.1658 - val_acc: 0.3844\n",
      "Epoch 199/1000\n",
      "28709/28709 [==============================] - 13s 450us/step - loss: 1.2092 - acc: 0.8599 - val_loss: 3.4984 - val_acc: 0.4048\n",
      "Epoch 200/1000\n",
      "28709/28709 [==============================] - 9s 327us/step - loss: 0.0405 - acc: 0.9932 - val_loss: 4.6182 - val_acc: 0.4034\n",
      "Epoch 201/1000\n",
      "28709/28709 [==============================] - 9s 323us/step - loss: 0.7103 - acc: 0.8995 - val_loss: 4.1638 - val_acc: 0.3992\n",
      "Epoch 202/1000\n",
      "28709/28709 [==============================] - 13s 451us/step - loss: 0.5447 - acc: 0.9112 - val_loss: 3.5205 - val_acc: 0.3993\n",
      "Epoch 203/1000\n",
      "28709/28709 [==============================] - 7s 245us/step - loss: 0.0283 - acc: 0.9956 - val_loss: 5.5685 - val_acc: 0.3625\n",
      "Epoch 204/1000\n",
      "28709/28709 [==============================] - 11s 395us/step - loss: 1.1253 - acc: 0.8525 - val_loss: 4.9032 - val_acc: 0.3971\n",
      "Epoch 205/1000\n",
      "28709/28709 [==============================] - 12s 434us/step - loss: 0.6699 - acc: 0.9102 - val_loss: 3.6479 - val_acc: 0.4004\n",
      "Epoch 206/1000\n",
      "28709/28709 [==============================] - 6s 226us/step - loss: 0.1037 - acc: 0.9850 - val_loss: 7.1967 - val_acc: 0.2763\n",
      "Epoch 207/1000\n",
      "28709/28709 [==============================] - 13s 444us/step - loss: 0.3955 - acc: 0.9305 - val_loss: 5.1750 - val_acc: 0.4010\n",
      "Epoch 208/1000\n",
      "28709/28709 [==============================] - 10s 360us/step - loss: 0.8418 - acc: 0.8770 - val_loss: 3.9996 - val_acc: 0.3981\n",
      "Epoch 209/1000\n",
      "28709/28709 [==============================] - 7s 258us/step - loss: 0.6458 - acc: 0.9046 - val_loss: 3.3205 - val_acc: 0.3953\n",
      "Epoch 210/1000\n",
      "28709/28709 [==============================] - 14s 475us/step - loss: 0.0330 - acc: 0.9957 - val_loss: 4.9566 - val_acc: 0.3844\n",
      "Epoch 211/1000\n",
      "28709/28709 [==============================] - 10s 335us/step - loss: 0.8805 - acc: 0.8807 - val_loss: 5.0401 - val_acc: 0.4066\n",
      "Epoch 212/1000\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 1.0452 - acc: 0.8682 - val_loss: 3.2305 - val_acc: 0.3984\n",
      "Epoch 213/1000\n",
      "28709/28709 [==============================] - 13s 461us/step - loss: 0.0589 - acc: 0.9887 - val_loss: 4.9866 - val_acc: 0.3908\n",
      "Epoch 214/1000\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.6724 - acc: 0.8976 - val_loss: 4.8024 - val_acc: 0.4045\n",
      "Epoch 215/1000\n",
      "28709/28709 [==============================] - 10s 331us/step - loss: 0.7346 - acc: 0.8924 - val_loss: 3.4774 - val_acc: 0.3940\n",
      "Epoch 216/1000\n",
      "28709/28709 [==============================] - 13s 443us/step - loss: 0.0382 - acc: 0.9935 - val_loss: 8.0659 - val_acc: 0.2685\n",
      "Epoch 217/1000\n",
      "28709/28709 [==============================] - 8s 263us/step - loss: 0.5431 - acc: 0.9125 - val_loss: 4.3211 - val_acc: 0.4020\n",
      "Epoch 218/1000\n",
      "28709/28709 [==============================] - 11s 391us/step - loss: 0.5671 - acc: 0.8999 - val_loss: 3.4937 - val_acc: 0.4010\n",
      "Epoch 219/1000\n",
      "28709/28709 [==============================] - 13s 461us/step - loss: 0.0245 - acc: 0.9961 - val_loss: 5.0933 - val_acc: 0.3918\n",
      "Epoch 220/1000\n",
      "28709/28709 [==============================] - 7s 248us/step - loss: 0.5821 - acc: 0.9033 - val_loss: 5.1099 - val_acc: 0.3984\n",
      "Epoch 221/1000\n",
      "28709/28709 [==============================] - 12s 403us/step - loss: 0.9199 - acc: 0.8739 - val_loss: 3.4673 - val_acc: 0.3988\n",
      "Epoch 222/1000\n",
      "28709/28709 [==============================] - 12s 418us/step - loss: 0.0316 - acc: 0.9942 - val_loss: 6.6131 - val_acc: 0.2834\n",
      "Epoch 223/1000\n",
      "28709/28709 [==============================] - 7s 247us/step - loss: 0.5127 - acc: 0.9184 - val_loss: 4.4538 - val_acc: 0.3991\n",
      "Epoch 224/1000\n",
      "28709/28709 [==============================] - 13s 448us/step - loss: 1.0267 - acc: 0.8765 - val_loss: 3.5649 - val_acc: 0.3977\n",
      "Epoch 225/1000\n",
      "28709/28709 [==============================] - 10s 354us/step - loss: 0.0641 - acc: 0.9871 - val_loss: 7.3380 - val_acc: 0.3226\n",
      "Epoch 226/1000\n",
      "28709/28709 [==============================] - 8s 289us/step - loss: 0.5545 - acc: 0.9006 - val_loss: 4.5256 - val_acc: 0.4080\n",
      "Epoch 227/1000\n",
      "28709/28709 [==============================] - 13s 460us/step - loss: 0.5011 - acc: 0.9184 - val_loss: 4.9063 - val_acc: 0.4043\n",
      "Epoch 228/1000\n",
      "28709/28709 [==============================] - 8s 277us/step - loss: 0.6652 - acc: 0.9077 - val_loss: 3.7306 - val_acc: 0.4023\n",
      "Epoch 229/1000\n",
      "28709/28709 [==============================] - 10s 357us/step - loss: 0.4292 - acc: 0.9377 - val_loss: 3.4515 - val_acc: 0.3897\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 13s 444us/step - loss: 0.0738 - acc: 0.9823 - val_loss: 4.9905 - val_acc: 0.4023\n",
      "Epoch 231/1000\n",
      "28709/28709 [==============================] - 6s 216us/step - loss: 0.8417 - acc: 0.8871 - val_loss: 4.1875 - val_acc: 0.4028\n",
      "Epoch 232/1000\n",
      "28709/28709 [==============================] - 13s 437us/step - loss: 0.6726 - acc: 0.8846 - val_loss: 3.3744 - val_acc: 0.4009\n",
      "Epoch 233/1000\n",
      "28709/28709 [==============================] - 11s 388us/step - loss: 0.0338 - acc: 0.9953 - val_loss: 5.0424 - val_acc: 0.3912\n",
      "Epoch 234/1000\n",
      "28709/28709 [==============================] - 8s 278us/step - loss: 0.7612 - acc: 0.9011 - val_loss: 4.9572 - val_acc: 0.3915\n",
      "Epoch 235/1000\n",
      "28709/28709 [==============================] - 14s 494us/step - loss: 1.0426 - acc: 0.8809 - val_loss: 3.8282 - val_acc: 0.3945\n",
      "Epoch 236/1000\n",
      "28709/28709 [==============================] - 10s 332us/step - loss: 0.1166 - acc: 0.9823 - val_loss: 10.1754 - val_acc: 0.2006\n",
      "Epoch 237/1000\n",
      "28709/28709 [==============================] - 10s 345us/step - loss: 0.8616 - acc: 0.8823 - val_loss: 4.9683 - val_acc: 0.3802\n",
      "Epoch 238/1000\n",
      "28709/28709 [==============================] - 13s 456us/step - loss: 0.4206 - acc: 0.9302 - val_loss: 4.2794 - val_acc: 0.4028\n",
      "Epoch 239/1000\n",
      "28709/28709 [==============================] - 7s 230us/step - loss: 1.1464 - acc: 0.8697 - val_loss: 3.7411 - val_acc: 0.3918\n",
      "Epoch 240/1000\n",
      "28709/28709 [==============================] - 12s 430us/step - loss: 0.7633 - acc: 0.9065 - val_loss: 3.2608 - val_acc: 0.3701\n",
      "Epoch 241/1000\n",
      "28709/28709 [==============================] - 12s 403us/step - loss: 0.0746 - acc: 0.9834 - val_loss: 4.4824 - val_acc: 0.4042\n",
      "Epoch 242/1000\n",
      "28709/28709 [==============================] - 7s 238us/step - loss: 0.5726 - acc: 0.9115 - val_loss: 4.8051 - val_acc: 0.3995\n",
      "Epoch 243/1000\n",
      "28709/28709 [==============================] - 13s 460us/step - loss: 0.7776 - acc: 0.8869 - val_loss: 3.3411 - val_acc: 0.4014\n",
      "Epoch 244/1000\n",
      "28709/28709 [==============================] - 9s 311us/step - loss: 0.0323 - acc: 0.9953 - val_loss: 5.2907 - val_acc: 0.3899\n",
      "Epoch 245/1000\n",
      "28709/28709 [==============================] - 9s 324us/step - loss: 0.8208 - acc: 0.8826 - val_loss: 3.8759 - val_acc: 0.3989\n",
      "Epoch 246/1000\n",
      "28709/28709 [==============================] - 13s 466us/step - loss: 0.1721 - acc: 0.9779 - val_loss: 10.0178 - val_acc: 0.3044\n",
      "Epoch 247/1000\n",
      "28709/28709 [==============================] - 7s 250us/step - loss: 1.2478 - acc: 0.8727 - val_loss: 5.2146 - val_acc: 0.3915\n",
      "Epoch 248/1000\n",
      "28709/28709 [==============================] - 11s 390us/step - loss: 0.3942 - acc: 0.9386 - val_loss: 5.0912 - val_acc: 0.3981\n",
      "Epoch 249/1000\n",
      "28709/28709 [==============================] - 13s 447us/step - loss: 0.9168 - acc: 0.8865 - val_loss: 3.4865 - val_acc: 0.3879\n",
      "Epoch 250/1000\n",
      "28709/28709 [==============================] - 7s 249us/step - loss: 0.0410 - acc: 0.9940 - val_loss: 5.9913 - val_acc: 0.3476\n",
      "Epoch 251/1000\n",
      "28709/28709 [==============================] - 11s 390us/step - loss: 0.5095 - acc: 0.9125 - val_loss: 5.0289 - val_acc: 0.4059\n",
      "Epoch 252/1000\n",
      "28709/28709 [==============================] - 13s 457us/step - loss: 0.7735 - acc: 0.8928 - val_loss: 3.6368 - val_acc: 0.3986\n",
      "Epoch 253/1000\n",
      "28709/28709 [==============================] - 7s 229us/step - loss: 0.0297 - acc: 0.9946 - val_loss: 5.2646 - val_acc: 0.3871\n",
      "Epoch 254/1000\n",
      "28709/28709 [==============================] - 12s 433us/step - loss: 0.8553 - acc: 0.8955 - val_loss: 4.4758 - val_acc: 0.4006\n",
      "Epoch 255/1000\n",
      "28709/28709 [==============================] - 11s 379us/step - loss: 0.8432 - acc: 0.8946 - val_loss: 3.6776 - val_acc: 0.4034\n",
      "Epoch 256/1000\n",
      "28709/28709 [==============================] - 7s 252us/step - loss: 0.5025 - acc: 0.9451 - val_loss: 7.1544 - val_acc: 0.3152\n",
      "Epoch 257/1000\n",
      "28709/28709 [==============================] - 13s 442us/step - loss: 0.2338 - acc: 0.9554 - val_loss: 5.2626 - val_acc: 0.3821\n",
      "Epoch 258/1000\n",
      "28709/28709 [==============================] - 11s 396us/step - loss: 0.3701 - acc: 0.9279 - val_loss: 5.3030 - val_acc: 0.4042\n",
      "Epoch 259/1000\n",
      "28709/28709 [==============================] - 7s 255us/step - loss: 1.0905 - acc: 0.8834 - val_loss: 3.7559 - val_acc: 0.4050\n",
      "Epoch 260/1000\n",
      "28709/28709 [==============================] - 13s 458us/step - loss: 0.0259 - acc: 0.9959 - val_loss: 9.9084 - val_acc: 0.2034\n",
      "Epoch 261/1000\n",
      "28709/28709 [==============================] - 10s 336us/step - loss: 1.0149 - acc: 0.8703 - val_loss: 4.0701 - val_acc: 0.3950\n",
      "Epoch 262/1000\n",
      "28709/28709 [==============================] - 9s 308us/step - loss: 1.2399 - acc: 0.8689 - val_loss: 3.6085 - val_acc: 0.4006\n",
      "Epoch 263/1000\n",
      "28709/28709 [==============================] - 13s 452us/step - loss: 0.0379 - acc: 0.9935 - val_loss: 4.4998 - val_acc: 0.3981\n",
      "Epoch 264/1000\n",
      "28709/28709 [==============================] - 8s 269us/step - loss: 1.6059 - acc: 0.8423 - val_loss: 3.8800 - val_acc: 0.3943\n",
      "Epoch 265/1000\n",
      "28709/28709 [==============================] - 11s 373us/step - loss: 0.0256 - acc: 0.9954 - val_loss: 5.2950 - val_acc: 0.4007\n",
      "Epoch 266/1000\n",
      "28709/28709 [==============================] - 13s 441us/step - loss: 0.7140 - acc: 0.9097 - val_loss: 5.4561 - val_acc: 0.3982\n",
      "Epoch 267/1000\n",
      "28709/28709 [==============================] - 6s 225us/step - loss: 1.4861 - acc: 0.8575 - val_loss: 3.8085 - val_acc: 0.3961\n",
      "Epoch 268/1000\n",
      "28709/28709 [==============================] - 13s 440us/step - loss: 0.0283 - acc: 0.9952 - val_loss: 5.2071 - val_acc: 0.3943\n",
      "Epoch 269/1000\n",
      "28709/28709 [==============================] - 12s 420us/step - loss: 0.9277 - acc: 0.8902 - val_loss: 4.6730 - val_acc: 0.3931\n",
      "Epoch 270/1000\n",
      "28709/28709 [==============================] - 7s 233us/step - loss: 0.6147 - acc: 0.9401 - val_loss: 5.5024 - val_acc: 0.3510\n",
      "Epoch 271/1000\n",
      "28709/28709 [==============================] - 13s 457us/step - loss: 0.2214 - acc: 0.9498 - val_loss: 5.6714 - val_acc: 0.3965\n",
      "Epoch 272/1000\n",
      "28709/28709 [==============================] - 11s 370us/step - loss: 0.5470 - acc: 0.9208 - val_loss: 3.8101 - val_acc: 0.4035\n",
      "Epoch 273/1000\n",
      "28709/28709 [==============================] - 8s 274us/step - loss: 0.0208 - acc: 0.9961 - val_loss: 6.8110 - val_acc: 0.2993\n",
      "Epoch 274/1000\n",
      "28709/28709 [==============================] - 13s 445us/step - loss: 0.7005 - acc: 0.8931 - val_loss: 4.3903 - val_acc: 0.3963\n",
      "Epoch 275/1000\n",
      "28709/28709 [==============================] - 10s 360us/step - loss: 1.0037 - acc: 0.8929 - val_loss: 3.7965 - val_acc: 0.4035\n",
      "Epoch 276/1000\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 0.0289 - acc: 0.9936 - val_loss: 5.7252 - val_acc: 0.3479\n",
      "Epoch 277/1000\n",
      "28709/28709 [==============================] - 14s 473us/step - loss: 0.5574 - acc: 0.9005 - val_loss: 4.8659 - val_acc: 0.3968\n",
      "Epoch 278/1000\n",
      "28709/28709 [==============================] - 9s 327us/step - loss: 0.8298 - acc: 0.9038 - val_loss: 3.9541 - val_acc: 0.4027\n",
      "Epoch 279/1000\n",
      "28709/28709 [==============================] - 10s 334us/step - loss: 0.0203 - acc: 0.9962 - val_loss: 5.4291 - val_acc: 0.3713\n",
      "Epoch 280/1000\n",
      "28709/28709 [==============================] - 13s 456us/step - loss: 0.5623 - acc: 0.9179 - val_loss: 4.5359 - val_acc: 0.3985\n",
      "Epoch 281/1000\n",
      "28709/28709 [==============================] - 10s 348us/step - loss: 0.2626 - acc: 0.9486 - val_loss: 4.6886 - val_acc: 0.3847\n",
      "Epoch 282/1000\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.4893 - acc: 0.9315 - val_loss: 5.5162 - val_acc: 0.4032\n",
      "Epoch 283/1000\n",
      "28709/28709 [==============================] - 13s 463us/step - loss: 0.5163 - acc: 0.9313 - val_loss: 5.1788 - val_acc: 0.3938\n",
      "Epoch 284/1000\n",
      "28709/28709 [==============================] - 8s 284us/step - loss: 0.6175 - acc: 0.9142 - val_loss: 5.2033 - val_acc: 0.3958\n",
      "Epoch 285/1000\n",
      "28709/28709 [==============================] - 11s 375us/step - loss: 0.7120 - acc: 0.9084 - val_loss: 3.5724 - val_acc: 0.3968\n",
      "Epoch 286/1000\n",
      "28709/28709 [==============================] - 13s 458us/step - loss: 0.0249 - acc: 0.9959 - val_loss: 5.3547 - val_acc: 0.4057\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 7s 249us/step - loss: 0.8267 - acc: 0.8980 - val_loss: 4.7202 - val_acc: 0.3942\n",
      "Epoch 288/1000\n",
      "28709/28709 [==============================] - 12s 401us/step - loss: 0.2812 - acc: 0.9641 - val_loss: 8.8973 - val_acc: 0.2543\n",
      "Epoch 289/1000\n",
      "28709/28709 [==============================] - 12s 433us/step - loss: 0.5455 - acc: 0.9350 - val_loss: 4.3695 - val_acc: 0.4007\n",
      "Epoch 290/1000\n",
      "28709/28709 [==============================] - 7s 261us/step - loss: 0.5340 - acc: 0.9151 - val_loss: 3.4491 - val_acc: 0.4024\n",
      "Epoch 291/1000\n",
      "28709/28709 [==============================] - 12s 421us/step - loss: 0.0240 - acc: 0.9966 - val_loss: 5.4906 - val_acc: 0.3777\n",
      "Epoch 292/1000\n",
      "28709/28709 [==============================] - 12s 432us/step - loss: 0.4786 - acc: 0.9298 - val_loss: 4.3900 - val_acc: 0.3997\n",
      "Epoch 293/1000\n",
      "28709/28709 [==============================] - 10s 334us/step - loss: 0.8149 - acc: 0.8860 - val_loss: 3.8996 - val_acc: 0.3768\n",
      "Epoch 294/1000\n",
      "28709/28709 [==============================] - 12s 423us/step - loss: 0.0264 - acc: 0.9943 - val_loss: 5.9196 - val_acc: 0.4043\n",
      "Epoch 295/1000\n",
      "28709/28709 [==============================] - 15s 511us/step - loss: 0.7256 - acc: 0.9217 - val_loss: 4.6577 - val_acc: 0.4004\n",
      "Epoch 296/1000\n",
      "28709/28709 [==============================] - 10s 358us/step - loss: 0.7922 - acc: 0.9011 - val_loss: 3.8104 - val_acc: 0.3985\n",
      "Epoch 297/1000\n",
      "28709/28709 [==============================] - 10s 352us/step - loss: 0.0223 - acc: 0.9966 - val_loss: 5.2520 - val_acc: 0.3991\n",
      "Epoch 298/1000\n",
      "28709/28709 [==============================] - 14s 493us/step - loss: 0.7223 - acc: 0.9065 - val_loss: 5.5059 - val_acc: 0.3964\n",
      "Epoch 299/1000\n",
      "28709/28709 [==============================] - 13s 446us/step - loss: 0.6644 - acc: 0.9048 - val_loss: 3.6605 - val_acc: 0.3965\n",
      "Epoch 300/1000\n",
      "28709/28709 [==============================] - 7s 254us/step - loss: 0.7249 - acc: 0.9212 - val_loss: 4.1823 - val_acc: 0.3708\n",
      "Epoch 301/1000\n",
      "28709/28709 [==============================] - 12s 433us/step - loss: 0.0649 - acc: 0.9837 - val_loss: 4.6711 - val_acc: 0.3938\n",
      "Epoch 302/1000\n",
      "28709/28709 [==============================] - 12s 406us/step - loss: 0.7705 - acc: 0.8975 - val_loss: 4.8259 - val_acc: 0.3978\n",
      "Epoch 303/1000\n",
      "28709/28709 [==============================] - 7s 260us/step - loss: 0.0150 - acc: 0.9965 - val_loss: 6.0379 - val_acc: 0.3783\n",
      "Epoch 304/1000\n",
      "28709/28709 [==============================] - 13s 448us/step - loss: 0.9102 - acc: 0.8984 - val_loss: 4.9292 - val_acc: 0.3993\n",
      "Epoch 305/1000\n",
      "28709/28709 [==============================] - 11s 368us/step - loss: 0.6877 - acc: 0.9073 - val_loss: 3.4983 - val_acc: 0.3929\n",
      "Epoch 306/1000\n",
      "28709/28709 [==============================] - 9s 326us/step - loss: 0.0272 - acc: 0.9954 - val_loss: 5.4458 - val_acc: 0.4010\n",
      "Epoch 307/1000\n",
      "28709/28709 [==============================] - 14s 484us/step - loss: 0.7385 - acc: 0.9035 - val_loss: 4.0454 - val_acc: 0.3985\n",
      "Epoch 308/1000\n",
      "28709/28709 [==============================] - 10s 340us/step - loss: 0.0140 - acc: 0.9968 - val_loss: 5.5507 - val_acc: 0.3744\n",
      "Epoch 309/1000\n",
      "28709/28709 [==============================] - 10s 357us/step - loss: 0.9040 - acc: 0.8910 - val_loss: 4.7069 - val_acc: 0.3982\n",
      "Epoch 310/1000\n",
      "28709/28709 [==============================] - 14s 487us/step - loss: 0.6008 - acc: 0.9179 - val_loss: 3.7732 - val_acc: 0.3887\n",
      "Epoch 311/1000\n",
      "28709/28709 [==============================] - 8s 275us/step - loss: 0.0254 - acc: 0.9957 - val_loss: 4.9171 - val_acc: 0.3893\n",
      "Epoch 312/1000\n",
      "28709/28709 [==============================] - 12s 425us/step - loss: 0.8090 - acc: 0.8974 - val_loss: 5.3073 - val_acc: 0.4017\n",
      "Epoch 313/1000\n",
      "28709/28709 [==============================] - 13s 444us/step - loss: 0.8806 - acc: 0.8959 - val_loss: 3.5053 - val_acc: 0.3910\n",
      "Epoch 314/1000\n",
      "28709/28709 [==============================] - 8s 267us/step - loss: 0.0294 - acc: 0.9951 - val_loss: 5.6321 - val_acc: 0.4014\n",
      "Epoch 315/1000\n",
      "28709/28709 [==============================] - 14s 474us/step - loss: 0.9350 - acc: 0.8893 - val_loss: 5.2749 - val_acc: 0.3984\n",
      "Epoch 316/1000\n",
      "28709/28709 [==============================] - 13s 449us/step - loss: 0.0146 - acc: 0.9960 - val_loss: 5.6677 - val_acc: 0.4039\n",
      "Epoch 317/1000\n",
      "28709/28709 [==============================] - 8s 285us/step - loss: 1.0911 - acc: 0.8772 - val_loss: 5.0051 - val_acc: 0.3954\n",
      "Epoch 318/1000\n",
      "28709/28709 [==============================] - 13s 458us/step - loss: 1.2736 - acc: 0.8720 - val_loss: 4.2940 - val_acc: 0.3940\n",
      "Epoch 319/1000\n",
      "28709/28709 [==============================] - 11s 394us/step - loss: 0.0203 - acc: 0.9948 - val_loss: 5.7271 - val_acc: 0.3963\n",
      "Epoch 320/1000\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.7114 - acc: 0.9216 - val_loss: 4.5107 - val_acc: 0.3926\n",
      "Epoch 321/1000\n",
      "28709/28709 [==============================] - 14s 473us/step - loss: 0.2757 - acc: 0.9411 - val_loss: 4.2188 - val_acc: 0.4018\n",
      "Epoch 322/1000\n",
      "28709/28709 [==============================] - 10s 358us/step - loss: 0.8403 - acc: 0.8936 - val_loss: 3.7666 - val_acc: 0.3875\n",
      "Epoch 323/1000\n",
      "28709/28709 [==============================] - 9s 329us/step - loss: 0.0258 - acc: 0.9943 - val_loss: 6.5787 - val_acc: 0.3591\n",
      "Epoch 324/1000\n",
      "28709/28709 [==============================] - 14s 489us/step - loss: 0.6740 - acc: 0.9162 - val_loss: 4.4746 - val_acc: 0.3978\n",
      "Epoch 325/1000\n",
      "28709/28709 [==============================] - 11s 371us/step - loss: 0.8437 - acc: 0.9025 - val_loss: 3.6600 - val_acc: 0.4002\n",
      "Epoch 326/1000\n",
      "28709/28709 [==============================] - 9s 308us/step - loss: 0.0163 - acc: 0.9967 - val_loss: 5.6612 - val_acc: 0.3963\n",
      "Epoch 327/1000\n",
      "28709/28709 [==============================] - 13s 465us/step - loss: 1.0004 - acc: 0.8841 - val_loss: 4.1488 - val_acc: 0.4066\n",
      "Epoch 328/1000\n",
      "28709/28709 [==============================] - 10s 349us/step - loss: 0.0162 - acc: 0.9961 - val_loss: 5.3589 - val_acc: 0.3584\n",
      "Epoch 329/1000\n",
      "28709/28709 [==============================] - 9s 329us/step - loss: 0.7862 - acc: 0.9016 - val_loss: 5.6951 - val_acc: 0.3942\n",
      "Epoch 330/1000\n",
      "28709/28709 [==============================] - 13s 468us/step - loss: 0.4737 - acc: 0.9286 - val_loss: 4.0533 - val_acc: 0.3928\n",
      "Epoch 331/1000\n",
      "28709/28709 [==============================] - 9s 326us/step - loss: 0.0141 - acc: 0.9961 - val_loss: 7.0934 - val_acc: 0.3433\n",
      "Epoch 332/1000\n",
      "28709/28709 [==============================] - 11s 370us/step - loss: 0.6282 - acc: 0.9140 - val_loss: 4.8507 - val_acc: 0.3967\n",
      "Epoch 333/1000\n",
      "28709/28709 [==============================] - 14s 499us/step - loss: 0.5505 - acc: 0.9271 - val_loss: 3.9040 - val_acc: 0.3991\n",
      "Epoch 334/1000\n",
      "28709/28709 [==============================] - 10s 347us/step - loss: 0.0274 - acc: 0.9944 - val_loss: 8.3098 - val_acc: 0.3242\n",
      "Epoch 335/1000\n",
      "28709/28709 [==============================] - 10s 363us/step - loss: 0.6264 - acc: 0.9163 - val_loss: 5.4092 - val_acc: 0.3897\n",
      "Epoch 336/1000\n",
      "28709/28709 [==============================] - 14s 499us/step - loss: 0.3525 - acc: 0.9429 - val_loss: 4.3682 - val_acc: 0.4025\n",
      "Epoch 337/1000\n",
      "28709/28709 [==============================] - 12s 404us/step - loss: 0.7288 - acc: 0.9106 - val_loss: 4.1597 - val_acc: 0.3981\n",
      "Epoch 338/1000\n",
      "28709/28709 [==============================] - 9s 320us/step - loss: 0.0170 - acc: 0.9957 - val_loss: 5.9841 - val_acc: 0.3953\n",
      "Epoch 339/1000\n",
      "28709/28709 [==============================] - 15s 511us/step - loss: 0.6390 - acc: 0.9252 - val_loss: 5.3498 - val_acc: 0.3968\n",
      "Epoch 340/1000\n",
      "28709/28709 [==============================] - 12s 433us/step - loss: 0.7525 - acc: 0.9122 - val_loss: 3.7517 - val_acc: 0.3977\n",
      "Epoch 341/1000\n",
      "28709/28709 [==============================] - 8s 293us/step - loss: 0.0180 - acc: 0.9965 - val_loss: 5.9320 - val_acc: 0.4037\n",
      "Epoch 342/1000\n",
      "28709/28709 [==============================] - 15s 513us/step - loss: 0.9025 - acc: 0.8987 - val_loss: 4.1017 - val_acc: 0.3977\n",
      "Epoch 343/1000\n",
      "28709/28709 [==============================] - 12s 420us/step - loss: 0.4782 - acc: 0.9547 - val_loss: 6.9252 - val_acc: 0.3255\n",
      "Epoch 344/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 9s 311us/step - loss: 0.3213 - acc: 0.9469 - val_loss: 5.2149 - val_acc: 0.3932\n",
      "Epoch 345/1000\n",
      "28709/28709 [==============================] - 14s 490us/step - loss: 1.2636 - acc: 0.8760 - val_loss: 3.8909 - val_acc: 0.4016\n",
      "Epoch 346/1000\n",
      "28709/28709 [==============================] - 13s 436us/step - loss: 0.0241 - acc: 0.9947 - val_loss: 5.6789 - val_acc: 0.3986\n",
      "Epoch 347/1000\n",
      "28709/28709 [==============================] - 8s 287us/step - loss: 0.9396 - acc: 0.9000 - val_loss: 3.9960 - val_acc: 0.4013\n",
      "Epoch 348/1000\n",
      "28709/28709 [==============================] - 14s 505us/step - loss: 0.0152 - acc: 0.9967 - val_loss: 5.7201 - val_acc: 0.3949\n",
      "Epoch 349/1000\n",
      "28709/28709 [==============================] - 12s 425us/step - loss: 0.9407 - acc: 0.8878 - val_loss: 4.6037 - val_acc: 0.3970\n",
      "Epoch 350/1000\n",
      "28709/28709 [==============================] - 8s 292us/step - loss: 0.1137 - acc: 0.9803 - val_loss: 10.0781 - val_acc: 0.2175\n",
      "Epoch 351/1000\n",
      "28709/28709 [==============================] - 14s 485us/step - loss: 0.6056 - acc: 0.9247 - val_loss: 4.5671 - val_acc: 0.3981\n",
      "Epoch 352/1000\n",
      "28709/28709 [==============================] - 13s 456us/step - loss: 0.6974 - acc: 0.9117 - val_loss: 3.8464 - val_acc: 0.3873\n",
      "Epoch 353/1000\n",
      "28709/28709 [==============================] - 8s 291us/step - loss: 0.0477 - acc: 0.9895 - val_loss: 4.3980 - val_acc: 0.4021\n",
      "Epoch 354/1000\n",
      "28709/28709 [==============================] - 14s 477us/step - loss: 0.9179 - acc: 0.8998 - val_loss: 3.8804 - val_acc: 0.3922\n",
      "Epoch 355/1000\n",
      "28709/28709 [==============================] - 13s 449us/step - loss: 0.0256 - acc: 0.9962 - val_loss: 4.7130 - val_acc: 0.3942\n",
      "Epoch 356/1000\n",
      "28709/28709 [==============================] - 10s 342us/step - loss: 0.7814 - acc: 0.9189 - val_loss: 4.4479 - val_acc: 0.3972\n",
      "Epoch 357/1000\n",
      "28709/28709 [==============================] - 14s 479us/step - loss: 0.0131 - acc: 0.9966 - val_loss: 5.7420 - val_acc: 0.3977\n",
      "Epoch 358/1000\n",
      "28709/28709 [==============================] - 15s 533us/step - loss: 0.8742 - acc: 0.8990 - val_loss: 4.3804 - val_acc: 0.3967\n",
      "Epoch 359/1000\n",
      "28709/28709 [==============================] - 10s 366us/step - loss: 0.0254 - acc: 0.9948 - val_loss: 8.6614 - val_acc: 0.3043\n",
      "Epoch 360/1000\n",
      "28709/28709 [==============================] - 11s 397us/step - loss: 0.6156 - acc: 0.9242 - val_loss: 5.7608 - val_acc: 0.3956\n",
      "Epoch 361/1000\n",
      "28709/28709 [==============================] - 14s 499us/step - loss: 0.6789 - acc: 0.9161 - val_loss: 4.0359 - val_acc: 0.4009\n",
      "Epoch 362/1000\n",
      "28709/28709 [==============================] - 10s 355us/step - loss: 0.0178 - acc: 0.9963 - val_loss: 5.9342 - val_acc: 0.3561\n",
      "Epoch 363/1000\n",
      "28709/28709 [==============================] - 10s 333us/step - loss: 0.4696 - acc: 0.9257 - val_loss: 4.5357 - val_acc: 0.4009\n",
      "Epoch 364/1000\n",
      "28709/28709 [==============================] - 14s 491us/step - loss: 0.6787 - acc: 0.9122 - val_loss: 3.8938 - val_acc: 0.4035\n",
      "Epoch 365/1000\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.0222 - acc: 0.9966 - val_loss: 6.0258 - val_acc: 0.3939\n",
      "Epoch 366/1000\n",
      "28709/28709 [==============================] - 11s 398us/step - loss: 0.7909 - acc: 0.9145 - val_loss: 5.0312 - val_acc: 0.3952\n",
      "Epoch 367/1000\n",
      "28709/28709 [==============================] - 14s 482us/step - loss: 0.0117 - acc: 0.9968 - val_loss: 6.0310 - val_acc: 0.3926\n",
      "Epoch 368/1000\n",
      "28709/28709 [==============================] - 8s 279us/step - loss: 1.0869 - acc: 0.8937 - val_loss: 5.0072 - val_acc: 0.3982\n",
      "Epoch 369/1000\n",
      "28709/28709 [==============================] - 14s 474us/step - loss: 1.0375 - acc: 0.8961 - val_loss: 4.3656 - val_acc: 0.3736\n",
      "Epoch 370/1000\n",
      "28709/28709 [==============================] - 11s 382us/step - loss: 0.0358 - acc: 0.9911 - val_loss: 5.6749 - val_acc: 0.3974\n",
      "Epoch 371/1000\n",
      "28709/28709 [==============================] - 10s 343us/step - loss: 0.7014 - acc: 0.9094 - val_loss: 4.0248 - val_acc: 0.3950\n",
      "Epoch 372/1000\n",
      "28709/28709 [==============================] - 15s 516us/step - loss: 0.0233 - acc: 0.9955 - val_loss: 5.7062 - val_acc: 0.3964\n",
      "Epoch 373/1000\n",
      "28709/28709 [==============================] - 8s 262us/step - loss: 0.8695 - acc: 0.8996 - val_loss: 4.1818 - val_acc: 0.4025\n",
      "Epoch 374/1000\n",
      "28709/28709 [==============================] - 13s 437us/step - loss: 0.0152 - acc: 0.9965 - val_loss: 6.6985 - val_acc: 0.3364\n",
      "Epoch 375/1000\n",
      "28709/28709 [==============================] - 12s 419us/step - loss: 0.9333 - acc: 0.8948 - val_loss: 4.4844 - val_acc: 0.3971\n",
      "Epoch 376/1000\n",
      "28709/28709 [==============================] - 9s 303us/step - loss: 0.8478 - acc: 0.9087 - val_loss: 4.2385 - val_acc: 0.3847\n",
      "Epoch 377/1000\n",
      "28709/28709 [==============================] - 15s 506us/step - loss: 0.0266 - acc: 0.9952 - val_loss: 4.8590 - val_acc: 0.3972\n",
      "Epoch 378/1000\n",
      "28709/28709 [==============================] - 10s 350us/step - loss: 1.3037 - acc: 0.8746 - val_loss: 4.4162 - val_acc: 0.3970\n",
      "Epoch 379/1000\n",
      "28709/28709 [==============================] - 11s 373us/step - loss: 0.0129 - acc: 0.9966 - val_loss: 5.8468 - val_acc: 0.3837\n",
      "Epoch 380/1000\n",
      "28709/28709 [==============================] - 13s 449us/step - loss: 0.8237 - acc: 0.9056 - val_loss: 4.9907 - val_acc: 0.4018\n",
      "Epoch 381/1000\n",
      "28709/28709 [==============================] - 8s 290us/step - loss: 0.7066 - acc: 0.9251 - val_loss: 4.1739 - val_acc: 0.3925\n",
      "Epoch 382/1000\n",
      "28709/28709 [==============================] - 13s 469us/step - loss: 0.0192 - acc: 0.9968 - val_loss: 5.4494 - val_acc: 0.3970\n",
      "Epoch 383/1000\n",
      "28709/28709 [==============================] - 12s 403us/step - loss: 0.9077 - acc: 0.8996 - val_loss: 5.5277 - val_acc: 0.3960\n",
      "Epoch 384/1000\n",
      "28709/28709 [==============================] - 9s 315us/step - loss: 0.3984 - acc: 0.9509 - val_loss: 5.4800 - val_acc: 0.3095\n",
      "Epoch 385/1000\n",
      "28709/28709 [==============================] - 15s 514us/step - loss: 0.1016 - acc: 0.9755 - val_loss: 5.7566 - val_acc: 0.3967\n",
      "Epoch 386/1000\n",
      "28709/28709 [==============================] - 7s 259us/step - loss: 0.8753 - acc: 0.8970 - val_loss: 4.1158 - val_acc: 0.3946\n",
      "Epoch 387/1000\n",
      "28709/28709 [==============================] - 13s 464us/step - loss: 0.0174 - acc: 0.9969 - val_loss: 5.8972 - val_acc: 0.3717\n",
      "Epoch 388/1000\n",
      "28709/28709 [==============================] - 11s 384us/step - loss: 0.4399 - acc: 0.9323 - val_loss: 4.5165 - val_acc: 0.4053\n",
      "Epoch 389/1000\n",
      "28709/28709 [==============================] - 10s 337us/step - loss: 1.3478 - acc: 0.8665 - val_loss: 4.3352 - val_acc: 0.3936\n",
      "Epoch 390/1000\n",
      "28709/28709 [==============================] - 14s 490us/step - loss: 0.0249 - acc: 0.9946 - val_loss: 5.3045 - val_acc: 0.3963\n",
      "Epoch 391/1000\n",
      "28709/28709 [==============================] - 8s 269us/step - loss: 0.6504 - acc: 0.9209 - val_loss: 5.4904 - val_acc: 0.3972\n",
      "Epoch 392/1000\n",
      "28709/28709 [==============================] - 13s 459us/step - loss: 0.0116 - acc: 0.9970 - val_loss: 6.7785 - val_acc: 0.3685\n",
      "Epoch 393/1000\n",
      "28709/28709 [==============================] - 11s 399us/step - loss: 1.9438 - acc: 0.8285 - val_loss: 5.9373 - val_acc: 0.3963\n",
      "Epoch 394/1000\n",
      "28709/28709 [==============================] - 10s 348us/step - loss: 1.2527 - acc: 0.8950 - val_loss: 4.6641 - val_acc: 0.3652\n",
      "Epoch 395/1000\n",
      "28709/28709 [==============================] - 15s 526us/step - loss: 0.0464 - acc: 0.9881 - val_loss: 5.9976 - val_acc: 0.4002\n",
      "Epoch 396/1000\n",
      "28709/28709 [==============================] - 10s 332us/step - loss: 0.9522 - acc: 0.8866 - val_loss: 5.8029 - val_acc: 0.3936\n",
      "Epoch 397/1000\n",
      "28709/28709 [==============================] - 11s 394us/step - loss: 0.0114 - acc: 0.9966 - val_loss: 5.9244 - val_acc: 0.3981\n",
      "Epoch 398/1000\n",
      "28709/28709 [==============================] - 13s 466us/step - loss: 0.7382 - acc: 0.9109 - val_loss: 4.4123 - val_acc: 0.3999\n",
      "Epoch 399/1000\n",
      "28709/28709 [==============================] - 9s 319us/step - loss: 0.0126 - acc: 0.9973 - val_loss: 6.0606 - val_acc: 0.3875\n",
      "Epoch 400/1000\n",
      "28709/28709 [==============================] - 14s 483us/step - loss: 0.7603 - acc: 0.9056 - val_loss: 5.7237 - val_acc: 0.4009\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 12s 403us/step - loss: 0.9223 - acc: 0.9016 - val_loss: 4.6956 - val_acc: 0.3971\n",
      "Epoch 402/1000\n",
      "28709/28709 [==============================] - 10s 349us/step - loss: 0.0121 - acc: 0.9965 - val_loss: 6.4758 - val_acc: 0.3986\n",
      "Epoch 403/1000\n",
      "28709/28709 [==============================] - 15s 529us/step - loss: 0.9167 - acc: 0.8891 - val_loss: 4.2725 - val_acc: 0.3953\n",
      "Epoch 404/1000\n",
      "28709/28709 [==============================] - 7s 258us/step - loss: 0.4506 - acc: 0.9543 - val_loss: 5.3739 - val_acc: 0.3676\n",
      "Epoch 405/1000\n",
      "28709/28709 [==============================] - 14s 496us/step - loss: 0.0995 - acc: 0.9744 - val_loss: 5.5433 - val_acc: 0.3989\n",
      "Epoch 406/1000\n",
      "28709/28709 [==============================] - 12s 434us/step - loss: 0.6584 - acc: 0.9221 - val_loss: 4.2165 - val_acc: 0.3991\n",
      "Epoch 407/1000\n",
      "28709/28709 [==============================] - 10s 342us/step - loss: 0.0146 - acc: 0.9968 - val_loss: 5.7355 - val_acc: 0.3991\n",
      "Epoch 408/1000\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 0.8460 - acc: 0.9051 - val_loss: 4.2361 - val_acc: 0.3925\n",
      "Epoch 409/1000\n",
      "28709/28709 [==============================] - 12s 402us/step - loss: 0.0206 - acc: 0.9966 - val_loss: 5.0535 - val_acc: 0.3979\n",
      "Epoch 410/1000\n",
      "28709/28709 [==============================] - 11s 394us/step - loss: 0.8108 - acc: 0.8968 - val_loss: 5.2156 - val_acc: 0.4037\n",
      "Epoch 411/1000\n",
      "28709/28709 [==============================] - 16s 564us/step - loss: 0.0560 - acc: 0.9877 - val_loss: 9.3977 - val_acc: 0.2776\n",
      "Epoch 412/1000\n",
      "28709/28709 [==============================] - 10s 343us/step - loss: 0.8659 - acc: 0.9062 - val_loss: 5.5770 - val_acc: 0.3946\n",
      "Epoch 413/1000\n",
      "28709/28709 [==============================] - 13s 436us/step - loss: 0.7199 - acc: 0.9182 - val_loss: 4.2888 - val_acc: 0.3800\n",
      "Epoch 414/1000\n",
      "28709/28709 [==============================] - 14s 497us/step - loss: 0.0541 - acc: 0.9841 - val_loss: 5.8831 - val_acc: 0.4013\n",
      "Epoch 415/1000\n",
      "28709/28709 [==============================] - 9s 310us/step - loss: 1.1311 - acc: 0.8878 - val_loss: 4.5431 - val_acc: 0.3993\n",
      "Epoch 416/1000\n",
      "28709/28709 [==============================] - 15s 524us/step - loss: 0.0171 - acc: 0.9966 - val_loss: 5.1596 - val_acc: 0.3815\n",
      "Epoch 417/1000\n",
      "28709/28709 [==============================] - 13s 464us/step - loss: 0.3429 - acc: 0.9413 - val_loss: 5.5532 - val_acc: 0.3992\n",
      "Epoch 418/1000\n",
      "28709/28709 [==============================] - 10s 362us/step - loss: 0.6712 - acc: 0.9168 - val_loss: 5.1588 - val_acc: 0.3887\n",
      "Epoch 419/1000\n",
      "28709/28709 [==============================] - 15s 532us/step - loss: 0.0100 - acc: 0.9964 - val_loss: 6.0389 - val_acc: 0.3922\n",
      "Epoch 420/1000\n",
      "28709/28709 [==============================] - 14s 493us/step - loss: 1.5765 - acc: 0.8520 - val_loss: 5.2940 - val_acc: 0.4016\n",
      "Epoch 421/1000\n",
      "28709/28709 [==============================] - 11s 382us/step - loss: 0.0151 - acc: 0.9958 - val_loss: 5.8673 - val_acc: 0.4017\n",
      "Epoch 422/1000\n",
      "28709/28709 [==============================] - 15s 529us/step - loss: 0.7479 - acc: 0.9134 - val_loss: 5.5916 - val_acc: 0.3975\n",
      "Epoch 423/1000\n",
      "28709/28709 [==============================] - 17s 601us/step - loss: 0.0103 - acc: 0.9965 - val_loss: 6.0322 - val_acc: 0.3984\n",
      "Epoch 424/1000\n",
      "28709/28709 [==============================] - 10s 360us/step - loss: 1.1105 - acc: 0.8824 - val_loss: 5.5309 - val_acc: 0.3946\n",
      "Epoch 425/1000\n",
      "28709/28709 [==============================] - 12s 422us/step - loss: 0.6114 - acc: 0.9258 - val_loss: 4.0186 - val_acc: 0.3953\n",
      "Epoch 426/1000\n",
      "28709/28709 [==============================] - 16s 540us/step - loss: 0.0199 - acc: 0.9968 - val_loss: 5.7586 - val_acc: 0.3974\n",
      "Epoch 427/1000\n",
      "28709/28709 [==============================] - 10s 352us/step - loss: 1.5565 - acc: 0.8533 - val_loss: 4.3943 - val_acc: 0.4016\n",
      "Epoch 428/1000\n",
      "28709/28709 [==============================] - 15s 511us/step - loss: 0.0164 - acc: 0.9966 - val_loss: 6.1975 - val_acc: 0.4027\n",
      "Epoch 429/1000\n",
      "28709/28709 [==============================] - 16s 574us/step - loss: 0.6379 - acc: 0.9168 - val_loss: 5.1417 - val_acc: 0.3986\n",
      "Epoch 430/1000\n",
      "28709/28709 [==============================] - 11s 372us/step - loss: 0.0095 - acc: 0.9968 - val_loss: 6.0223 - val_acc: 0.3861\n",
      "Epoch 431/1000\n",
      "28709/28709 [==============================] - 13s 460us/step - loss: 0.7204 - acc: 0.9203 - val_loss: 4.7275 - val_acc: 0.4021\n",
      "Epoch 432/1000\n",
      "28709/28709 [==============================] - 17s 593us/step - loss: 0.0217 - acc: 0.9947 - val_loss: 7.5295 - val_acc: 0.3297\n",
      "Epoch 433/1000\n",
      "28709/28709 [==============================] - 12s 402us/step - loss: 0.3630 - acc: 0.9386 - val_loss: 5.5861 - val_acc: 0.4032\n",
      "Epoch 434/1000\n",
      "28709/28709 [==============================] - 12s 408us/step - loss: 1.0410 - acc: 0.8957 - val_loss: 4.0515 - val_acc: 0.3971\n",
      "Epoch 435/1000\n",
      "28709/28709 [==============================] - 16s 547us/step - loss: 0.0253 - acc: 0.9955 - val_loss: 4.8987 - val_acc: 0.4080\n",
      "Epoch 436/1000\n",
      "28709/28709 [==============================] - 9s 315us/step - loss: 0.5899 - acc: 0.9267 - val_loss: 4.5241 - val_acc: 0.3986\n",
      "Epoch 437/1000\n",
      "28709/28709 [==============================] - 12s 401us/step - loss: 0.6072 - acc: 0.9437 - val_loss: 6.9676 - val_acc: 0.3368\n",
      "Epoch 438/1000\n",
      "28709/28709 [==============================] - 14s 499us/step - loss: 0.1957 - acc: 0.9639 - val_loss: 5.8824 - val_acc: 0.3953\n",
      "Epoch 439/1000\n",
      "28709/28709 [==============================] - 9s 323us/step - loss: 1.1151 - acc: 0.8882 - val_loss: 4.6651 - val_acc: 0.3586\n",
      "Epoch 440/1000\n",
      "28709/28709 [==============================] - 13s 469us/step - loss: 0.0414 - acc: 0.9889 - val_loss: 6.0289 - val_acc: 0.3967\n",
      "Epoch 441/1000\n",
      "28709/28709 [==============================] - 14s 479us/step - loss: 1.2068 - acc: 0.8929 - val_loss: 4.7310 - val_acc: 0.3875\n",
      "Epoch 442/1000\n",
      "28709/28709 [==============================] - 9s 296us/step - loss: 0.0162 - acc: 0.9952 - val_loss: 6.0596 - val_acc: 0.3965\n",
      "Epoch 443/1000\n",
      "28709/28709 [==============================] - 16s 542us/step - loss: 0.7543 - acc: 0.9180 - val_loss: 5.3322 - val_acc: 0.4030\n",
      "Epoch 444/1000\n",
      "28709/28709 [==============================] - 13s 464us/step - loss: 0.0120 - acc: 0.9964 - val_loss: 6.3249 - val_acc: 0.3574\n",
      "Epoch 445/1000\n",
      "28709/28709 [==============================] - 10s 356us/step - loss: 0.9274 - acc: 0.9043 - val_loss: 5.3937 - val_acc: 0.3952\n",
      "Epoch 446/1000\n",
      "28709/28709 [==============================] - 16s 563us/step - loss: 0.8049 - acc: 0.9031 - val_loss: 4.3401 - val_acc: 0.3928\n",
      "Epoch 447/1000\n",
      "28709/28709 [==============================] - 13s 438us/step - loss: 0.0155 - acc: 0.9967 - val_loss: 5.9241 - val_acc: 0.3960\n",
      "Epoch 448/1000\n",
      "28709/28709 [==============================] - 11s 369us/step - loss: 1.5394 - acc: 0.8683 - val_loss: 5.4595 - val_acc: 0.3453\n",
      "Epoch 449/1000\n",
      "28709/28709 [==============================] - 16s 567us/step - loss: 0.0958 - acc: 0.9766 - val_loss: 5.0322 - val_acc: 0.4027\n",
      "Epoch 450/1000\n",
      "28709/28709 [==============================] - 10s 339us/step - loss: 0.8888 - acc: 0.9009 - val_loss: 4.2861 - val_acc: 0.3988\n",
      "Epoch 451/1000\n",
      "28709/28709 [==============================] - 13s 438us/step - loss: 0.0156 - acc: 0.9968 - val_loss: 6.3283 - val_acc: 0.4055\n",
      "Epoch 452/1000\n",
      "28709/28709 [==============================] - 15s 510us/step - loss: 0.6382 - acc: 0.9292 - val_loss: 4.7038 - val_acc: 0.3982\n",
      "Epoch 453/1000\n",
      "28709/28709 [==============================] - 10s 349us/step - loss: 0.5152 - acc: 0.9452 - val_loss: 6.7962 - val_acc: 0.3163\n",
      "Epoch 454/1000\n",
      "28709/28709 [==============================] - 13s 442us/step - loss: 0.1585 - acc: 0.9701 - val_loss: 5.5377 - val_acc: 0.3889\n",
      "Epoch 455/1000\n",
      "28709/28709 [==============================] - 14s 477us/step - loss: 0.3873 - acc: 0.9394 - val_loss: 4.6866 - val_acc: 0.4020\n",
      "Epoch 456/1000\n",
      "28709/28709 [==============================] - 9s 325us/step - loss: 0.2555 - acc: 0.9704 - val_loss: 8.4110 - val_acc: 0.2898\n",
      "Epoch 457/1000\n",
      "28709/28709 [==============================] - 15s 515us/step - loss: 0.3216 - acc: 0.9588 - val_loss: 4.9506 - val_acc: 0.4013\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 12s 402us/step - loss: 0.8249 - acc: 0.9230 - val_loss: 5.4778 - val_acc: 0.3717\n",
      "Epoch 459/1000\n",
      "28709/28709 [==============================] - 10s 356us/step - loss: 0.0489 - acc: 0.9863 - val_loss: 5.7392 - val_acc: 0.3993\n",
      "Epoch 460/1000\n",
      "28709/28709 [==============================] - 16s 551us/step - loss: 0.9349 - acc: 0.9081 - val_loss: 4.8585 - val_acc: 0.3943\n",
      "Epoch 461/1000\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.0145 - acc: 0.9965 - val_loss: 5.9797 - val_acc: 0.3786\n",
      "Epoch 462/1000\n",
      "28709/28709 [==============================] - 14s 484us/step - loss: 0.5059 - acc: 0.9349 - val_loss: 5.8094 - val_acc: 0.3791\n",
      "Epoch 463/1000\n",
      "28709/28709 [==============================] - 13s 458us/step - loss: 0.3735 - acc: 0.9411 - val_loss: 5.0475 - val_acc: 0.3975\n",
      "Epoch 464/1000\n",
      "28709/28709 [==============================] - 9s 324us/step - loss: 1.1923 - acc: 0.8994 - val_loss: 6.6720 - val_acc: 0.3037\n",
      "Epoch 465/1000\n",
      "28709/28709 [==============================] - 14s 497us/step - loss: 0.1503 - acc: 0.9703 - val_loss: 5.1474 - val_acc: 0.3988\n",
      "Epoch 466/1000\n",
      "28709/28709 [==============================] - 12s 431us/step - loss: 0.5188 - acc: 0.9485 - val_loss: 5.6517 - val_acc: 0.3625\n",
      "Epoch 467/1000\n",
      "28709/28709 [==============================] - 9s 330us/step - loss: 0.0736 - acc: 0.9803 - val_loss: 5.2459 - val_acc: 0.4006\n",
      "Epoch 468/1000\n",
      "28709/28709 [==============================] - 16s 547us/step - loss: 0.5265 - acc: 0.9290 - val_loss: 4.6480 - val_acc: 0.4048\n",
      "Epoch 469/1000\n",
      "28709/28709 [==============================] - 12s 401us/step - loss: 0.0113 - acc: 0.9971 - val_loss: 6.0060 - val_acc: 0.4035\n",
      "Epoch 470/1000\n",
      "28709/28709 [==============================] - 10s 357us/step - loss: 1.4180 - acc: 0.8677 - val_loss: 4.9303 - val_acc: 0.3996\n",
      "Epoch 471/1000\n",
      "28709/28709 [==============================] - 15s 534us/step - loss: 0.0112 - acc: 0.9970 - val_loss: 5.4889 - val_acc: 0.3945\n",
      "Epoch 472/1000\n",
      "28709/28709 [==============================] - 9s 321us/step - loss: 0.7285 - acc: 0.9215 - val_loss: 5.1133 - val_acc: 0.3928\n",
      "Epoch 473/1000\n",
      "28709/28709 [==============================] - 13s 462us/step - loss: 0.0104 - acc: 0.9968 - val_loss: 6.0420 - val_acc: 0.3972\n",
      "Epoch 474/1000\n",
      "28709/28709 [==============================] - 17s 583us/step - loss: 1.1059 - acc: 0.8897 - val_loss: 6.6143 - val_acc: 0.3981\n",
      "Epoch 475/1000\n",
      "28709/28709 [==============================] - 14s 482us/step - loss: 0.2848 - acc: 0.9670 - val_loss: 9.2864 - val_acc: 0.3099\n",
      "Epoch 476/1000\n",
      "28709/28709 [==============================] - 8s 281us/step - loss: 0.7897 - acc: 0.9244 - val_loss: 6.0179 - val_acc: 0.3975\n",
      "Epoch 477/1000\n",
      "28709/28709 [==============================] - 14s 474us/step - loss: 0.4139 - acc: 0.9417 - val_loss: 4.7734 - val_acc: 0.3691\n",
      "Epoch 478/1000\n",
      "28709/28709 [==============================] - 11s 377us/step - loss: 0.0186 - acc: 0.9944 - val_loss: 6.2008 - val_acc: 0.3914\n",
      "Epoch 479/1000\n",
      "28709/28709 [==============================] - 10s 338us/step - loss: 1.0474 - acc: 0.8967 - val_loss: 4.7839 - val_acc: 0.4031\n",
      "Epoch 480/1000\n",
      "28709/28709 [==============================] - 15s 519us/step - loss: 0.0130 - acc: 0.9971 - val_loss: 5.7405 - val_acc: 0.3993\n",
      "Epoch 481/1000\n",
      "28709/28709 [==============================] - 8s 288us/step - loss: 1.4644 - acc: 0.8670 - val_loss: 4.9163 - val_acc: 0.3982\n",
      "Epoch 482/1000\n",
      "28709/28709 [==============================] - 12s 431us/step - loss: 0.0144 - acc: 0.9966 - val_loss: 5.4135 - val_acc: 0.3931\n",
      "Epoch 483/1000\n",
      "28709/28709 [==============================] - 14s 482us/step - loss: 0.7377 - acc: 0.9242 - val_loss: 5.4615 - val_acc: 0.3931\n",
      "Epoch 484/1000\n",
      "28709/28709 [==============================] - 8s 268us/step - loss: 0.0103 - acc: 0.9966 - val_loss: 6.3213 - val_acc: 0.3946\n",
      "Epoch 485/1000\n",
      "28709/28709 [==============================] - 14s 471us/step - loss: 0.8971 - acc: 0.9046 - val_loss: 4.9240 - val_acc: 0.4009\n",
      "Epoch 486/1000\n",
      "28709/28709 [==============================] - 11s 371us/step - loss: 0.0088 - acc: 0.9971 - val_loss: 6.0578 - val_acc: 0.3943\n",
      "Epoch 487/1000\n",
      "28709/28709 [==============================] - 10s 347us/step - loss: 1.0145 - acc: 0.8951 - val_loss: 5.0292 - val_acc: 0.3991\n",
      "Epoch 488/1000\n",
      "28709/28709 [==============================] - 14s 499us/step - loss: 0.0122 - acc: 0.9970 - val_loss: 6.0870 - val_acc: 0.4021\n",
      "Epoch 489/1000\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 1.0923 - acc: 0.8940 - val_loss: 5.1619 - val_acc: 0.4009\n",
      "Epoch 490/1000\n",
      "28709/28709 [==============================] - 13s 457us/step - loss: 0.0106 - acc: 0.9968 - val_loss: 6.1843 - val_acc: 0.3984\n",
      "Epoch 491/1000\n",
      "28709/28709 [==============================] - 12s 419us/step - loss: 0.6936 - acc: 0.9250 - val_loss: 6.2859 - val_acc: 0.3999\n",
      "Epoch 492/1000\n",
      "28709/28709 [==============================] - 9s 328us/step - loss: 1.1390 - acc: 0.9057 - val_loss: 6.6628 - val_acc: 0.3316\n",
      "Epoch 493/1000\n",
      "28709/28709 [==============================] - 14s 502us/step - loss: 0.1487 - acc: 0.9695 - val_loss: 5.2275 - val_acc: 0.4053\n",
      "Epoch 494/1000\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.7754 - acc: 0.9301 - val_loss: 6.1617 - val_acc: 0.3348\n",
      "Epoch 495/1000\n",
      "28709/28709 [==============================] - 13s 440us/step - loss: 0.0926 - acc: 0.9749 - val_loss: 6.0734 - val_acc: 0.3970\n",
      "Epoch 496/1000\n",
      "28709/28709 [==============================] - 13s 444us/step - loss: 0.4001 - acc: 0.9405 - val_loss: 4.9551 - val_acc: 0.3963\n",
      "Epoch 497/1000\n",
      "28709/28709 [==============================] - 9s 311us/step - loss: 0.0100 - acc: 0.9969 - val_loss: 6.3238 - val_acc: 0.4041\n",
      "Epoch 498/1000\n",
      "28709/28709 [==============================] - 17s 588us/step - loss: 0.6524 - acc: 0.9251 - val_loss: 5.1193 - val_acc: 0.4000\n",
      "Epoch 499/1000\n",
      "28709/28709 [==============================] - 14s 490us/step - loss: 0.0119 - acc: 0.9966 - val_loss: 7.1889 - val_acc: 0.3357\n",
      "Epoch 500/1000\n",
      "28709/28709 [==============================] - 9s 304us/step - loss: 0.8509 - acc: 0.9118 - val_loss: 5.2515 - val_acc: 0.3993\n",
      "Epoch 501/1000\n",
      "28709/28709 [==============================] - 15s 508us/step - loss: 0.7967 - acc: 0.9117 - val_loss: 4.9232 - val_acc: 0.3972\n",
      "Epoch 502/1000\n",
      "28709/28709 [==============================] - 10s 343us/step - loss: 0.0135 - acc: 0.9968 - val_loss: 5.2205 - val_acc: 0.3996\n",
      "Epoch 503/1000\n",
      "28709/28709 [==============================] - 10s 366us/step - loss: 1.1960 - acc: 0.8843 - val_loss: 5.2104 - val_acc: 0.3875\n",
      "Epoch 504/1000\n",
      "28709/28709 [==============================] - 13s 455us/step - loss: 0.0162 - acc: 0.9956 - val_loss: 5.9553 - val_acc: 0.3861\n",
      "Epoch 505/1000\n",
      "28709/28709 [==============================] - 8s 269us/step - loss: 0.5096 - acc: 0.9317 - val_loss: 5.9784 - val_acc: 0.3981\n",
      "Epoch 506/1000\n",
      "28709/28709 [==============================] - 15s 516us/step - loss: 0.0231 - acc: 0.9940 - val_loss: 9.8846 - val_acc: 0.2300\n",
      "Epoch 507/1000\n",
      "28709/28709 [==============================] - 10s 352us/step - loss: 0.6575 - acc: 0.9174 - val_loss: 5.2816 - val_acc: 0.4024\n",
      "Epoch 508/1000\n",
      "28709/28709 [==============================] - 12s 402us/step - loss: 0.2592 - acc: 0.9722 - val_loss: 9.2073 - val_acc: 0.2805\n",
      "Epoch 509/1000\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 0.5971 - acc: 0.9327 - val_loss: 5.2269 - val_acc: 0.4010\n",
      "Epoch 510/1000\n",
      "28709/28709 [==============================] - 9s 327us/step - loss: 0.0100 - acc: 0.9967 - val_loss: 5.9169 - val_acc: 0.3815\n",
      "Epoch 511/1000\n",
      "28709/28709 [==============================] - 13s 459us/step - loss: 0.7332 - acc: 0.9181 - val_loss: 6.1645 - val_acc: 0.3958\n",
      "Epoch 512/1000\n",
      "28709/28709 [==============================] - 15s 528us/step - loss: 0.0096 - acc: 0.9970 - val_loss: 6.7282 - val_acc: 0.3801\n",
      "Epoch 513/1000\n",
      "28709/28709 [==============================] - 9s 325us/step - loss: 0.7661 - acc: 0.9118 - val_loss: 5.4997 - val_acc: 0.3964\n",
      "Epoch 514/1000\n",
      "28709/28709 [==============================] - 14s 483us/step - loss: 0.0091 - acc: 0.9968 - val_loss: 6.1843 - val_acc: 0.3921\n",
      "Epoch 515/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 14s 495us/step - loss: 0.9068 - acc: 0.9031 - val_loss: 5.8206 - val_acc: 0.3967\n",
      "Epoch 516/1000\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.0091 - acc: 0.9971 - val_loss: 6.3888 - val_acc: 0.3954\n",
      "Epoch 517/1000\n",
      "28709/28709 [==============================] - 14s 499us/step - loss: 1.0151 - acc: 0.9014 - val_loss: 5.1861 - val_acc: 0.3965\n",
      "Epoch 518/1000\n",
      "28709/28709 [==============================] - 12s 434us/step - loss: 0.0107 - acc: 0.9966 - val_loss: 5.4209 - val_acc: 0.3984\n",
      "Epoch 519/1000\n",
      "28709/28709 [==============================] - 10s 353us/step - loss: 0.9984 - acc: 0.8987 - val_loss: 5.6413 - val_acc: 0.3965\n",
      "Epoch 520/1000\n",
      "28709/28709 [==============================] - 16s 557us/step - loss: 0.0105 - acc: 0.9966 - val_loss: 6.3308 - val_acc: 0.3922\n",
      "Epoch 521/1000\n",
      "28709/28709 [==============================] - 11s 392us/step - loss: 0.8441 - acc: 0.9085 - val_loss: 4.9838 - val_acc: 0.4003\n",
      "Epoch 522/1000\n",
      "28709/28709 [==============================] - 11s 398us/step - loss: 0.0108 - acc: 0.9972 - val_loss: 5.3775 - val_acc: 0.3982\n",
      "Epoch 523/1000\n",
      "28709/28709 [==============================] - 17s 586us/step - loss: 0.8652 - acc: 0.9127 - val_loss: 5.2911 - val_acc: 0.3931\n",
      "Epoch 524/1000\n",
      "28709/28709 [==============================] - 14s 476us/step - loss: 0.0109 - acc: 0.9972 - val_loss: 5.4781 - val_acc: 0.4000\n",
      "Epoch 525/1000\n",
      "28709/28709 [==============================] - 11s 392us/step - loss: 0.8878 - acc: 0.9075 - val_loss: 5.3647 - val_acc: 0.3975\n",
      "Epoch 526/1000\n",
      "28709/28709 [==============================] - 15s 538us/step - loss: 0.0113 - acc: 0.9967 - val_loss: 6.1214 - val_acc: 0.3970\n",
      "Epoch 527/1000\n",
      "28709/28709 [==============================] - 14s 497us/step - loss: 1.3443 - acc: 0.8823 - val_loss: 5.4294 - val_acc: 0.3911\n",
      "Epoch 528/1000\n",
      "28709/28709 [==============================] - 10s 354us/step - loss: 0.0126 - acc: 0.9961 - val_loss: 5.6117 - val_acc: 0.3932\n",
      "Epoch 529/1000\n",
      "28709/28709 [==============================] - 15s 519us/step - loss: 1.0907 - acc: 0.8858 - val_loss: 5.4042 - val_acc: 0.3968\n",
      "Epoch 530/1000\n",
      "28709/28709 [==============================] - 13s 454us/step - loss: 0.0124 - acc: 0.9964 - val_loss: 5.5319 - val_acc: 0.3991\n",
      "Epoch 531/1000\n",
      "28709/28709 [==============================] - 12s 409us/step - loss: 1.1128 - acc: 0.8984 - val_loss: 5.7367 - val_acc: 0.3712\n",
      "Epoch 532/1000\n",
      "28709/28709 [==============================] - 16s 540us/step - loss: 0.0407 - acc: 0.9881 - val_loss: 6.1265 - val_acc: 0.3984\n",
      "Epoch 533/1000\n",
      "28709/28709 [==============================] - 14s 470us/step - loss: 0.3901 - acc: 0.9642 - val_loss: 8.3574 - val_acc: 0.2913\n",
      "Epoch 534/1000\n",
      "28709/28709 [==============================] - 10s 337us/step - loss: 0.2571 - acc: 0.9617 - val_loss: 6.1855 - val_acc: 0.3965\n",
      "Epoch 535/1000\n",
      "28709/28709 [==============================] - 17s 589us/step - loss: 0.7788 - acc: 0.9302 - val_loss: 5.7803 - val_acc: 0.3599\n",
      "Epoch 536/1000\n",
      "28709/28709 [==============================] - 13s 454us/step - loss: 0.0542 - acc: 0.9849 - val_loss: 5.9701 - val_acc: 0.3997\n",
      "Epoch 537/1000\n",
      "28709/28709 [==============================] - 11s 390us/step - loss: 0.6202 - acc: 0.9241 - val_loss: 5.0537 - val_acc: 0.3967\n",
      "Epoch 538/1000\n",
      "28709/28709 [==============================] - 17s 609us/step - loss: 0.0097 - acc: 0.9973 - val_loss: 5.3849 - val_acc: 0.3945\n",
      "Epoch 539/1000\n",
      "28709/28709 [==============================] - 11s 394us/step - loss: 1.1009 - acc: 0.8903 - val_loss: 5.3477 - val_acc: 0.3940\n",
      "Epoch 540/1000\n",
      "28709/28709 [==============================] - 13s 446us/step - loss: 0.0148 - acc: 0.9961 - val_loss: 5.7758 - val_acc: 0.3903\n",
      "Epoch 541/1000\n",
      "28709/28709 [==============================] - 17s 594us/step - loss: 0.7869 - acc: 0.9104 - val_loss: 5.2874 - val_acc: 0.4007\n",
      "Epoch 542/1000\n",
      "28709/28709 [==============================] - 12s 418us/step - loss: 0.0092 - acc: 0.9973 - val_loss: 5.5450 - val_acc: 0.3947\n",
      "Epoch 543/1000\n",
      "28709/28709 [==============================] - 13s 436us/step - loss: 0.7483 - acc: 0.9186 - val_loss: 5.2979 - val_acc: 0.4006\n",
      "Epoch 544/1000\n",
      "28709/28709 [==============================] - 16s 564us/step - loss: 0.0125 - acc: 0.9964 - val_loss: 6.1515 - val_acc: 0.3986\n",
      "Epoch 545/1000\n",
      "28709/28709 [==============================] - 10s 365us/step - loss: 0.7889 - acc: 0.9176 - val_loss: 5.3403 - val_acc: 0.4007\n",
      "Epoch 546/1000\n",
      "28709/28709 [==============================] - 16s 546us/step - loss: 0.0107 - acc: 0.9967 - val_loss: 5.7381 - val_acc: 0.4000\n",
      "Epoch 547/1000\n",
      "28709/28709 [==============================] - 14s 495us/step - loss: 0.9638 - acc: 0.9040 - val_loss: 5.3930 - val_acc: 0.4024\n",
      "Epoch 548/1000\n",
      "28709/28709 [==============================] - 10s 355us/step - loss: 0.0095 - acc: 0.9968 - val_loss: 6.1085 - val_acc: 0.3956\n",
      "Epoch 549/1000\n",
      "28709/28709 [==============================] - 17s 603us/step - loss: 0.8429 - acc: 0.9074 - val_loss: 5.4858 - val_acc: 0.3960\n",
      "Epoch 550/1000\n",
      "28709/28709 [==============================] - 11s 396us/step - loss: 0.0096 - acc: 0.9967 - val_loss: 6.5001 - val_acc: 0.3775\n",
      "Epoch 551/1000\n",
      "28709/28709 [==============================] - 14s 491us/step - loss: 0.5316 - acc: 0.9321 - val_loss: 6.4278 - val_acc: 0.3901\n",
      "Epoch 552/1000\n",
      "28709/28709 [==============================] - 15s 528us/step - loss: 0.0098 - acc: 0.9965 - val_loss: 6.2771 - val_acc: 0.4052\n",
      "Epoch 553/1000\n",
      "28709/28709 [==============================] - 10s 333us/step - loss: 0.7169 - acc: 0.9183 - val_loss: 5.4367 - val_acc: 0.3865\n",
      "Epoch 554/1000\n",
      "28709/28709 [==============================] - 15s 519us/step - loss: 0.0116 - acc: 0.9965 - val_loss: 5.8111 - val_acc: 0.3978\n",
      "Epoch 555/1000\n",
      "28709/28709 [==============================] - 13s 455us/step - loss: 1.5185 - acc: 0.8693 - val_loss: 5.6611 - val_acc: 0.3982\n",
      "Epoch 556/1000\n",
      "28709/28709 [==============================] - 11s 394us/step - loss: 0.0103 - acc: 0.9966 - val_loss: 6.2761 - val_acc: 0.4017\n",
      "Epoch 557/1000\n",
      "28709/28709 [==============================] - 16s 548us/step - loss: 0.5550 - acc: 0.9313 - val_loss: 5.2851 - val_acc: 0.4037\n",
      "Epoch 558/1000\n",
      "28709/28709 [==============================] - 9s 310us/step - loss: 0.0098 - acc: 0.9967 - val_loss: 5.6647 - val_acc: 0.3984\n",
      "Epoch 559/1000\n",
      "28709/28709 [==============================] - 15s 506us/step - loss: 0.8027 - acc: 0.9190 - val_loss: 5.3909 - val_acc: 0.3958\n",
      "Epoch 560/1000\n",
      "28709/28709 [==============================] - 10s 354us/step - loss: 0.0089 - acc: 0.9971 - val_loss: 5.8699 - val_acc: 0.3939\n",
      "Epoch 561/1000\n",
      "28709/28709 [==============================] - 13s 443us/step - loss: 0.7360 - acc: 0.9184 - val_loss: 6.4196 - val_acc: 0.3956\n",
      "Epoch 562/1000\n",
      "28709/28709 [==============================] - 12s 424us/step - loss: 0.0076 - acc: 0.9970 - val_loss: 6.3844 - val_acc: 0.3924\n",
      "Epoch 563/1000\n",
      "28709/28709 [==============================] - 11s 391us/step - loss: 0.5797 - acc: 0.9330 - val_loss: 6.2122 - val_acc: 0.3932\n",
      "Epoch 564/1000\n",
      "28709/28709 [==============================] - 18s 612us/step - loss: 0.0081 - acc: 0.9969 - val_loss: 6.3920 - val_acc: 0.3912\n",
      "Epoch 565/1000\n",
      "28709/28709 [==============================] - 10s 350us/step - loss: 0.7071 - acc: 0.9258 - val_loss: 6.4358 - val_acc: 0.4009\n",
      "Epoch 566/1000\n",
      "28709/28709 [==============================] - 14s 474us/step - loss: 0.6391 - acc: 0.9233 - val_loss: 5.2097 - val_acc: 0.4007\n",
      "Epoch 567/1000\n",
      "28709/28709 [==============================] - 11s 397us/step - loss: 0.0167 - acc: 0.9955 - val_loss: 6.1262 - val_acc: 0.3953\n",
      "Epoch 568/1000\n",
      "28709/28709 [==============================] - 12s 420us/step - loss: 0.1947 - acc: 0.9770 - val_loss: 9.9694 - val_acc: 0.3015\n",
      "Epoch 569/1000\n",
      "28709/28709 [==============================] - 13s 451us/step - loss: 0.7575 - acc: 0.9248 - val_loss: 6.1596 - val_acc: 0.3952\n",
      "Epoch 570/1000\n",
      "28709/28709 [==============================] - 10s 363us/step - loss: 1.0512 - acc: 0.9021 - val_loss: 5.3724 - val_acc: 0.3939\n",
      "Epoch 571/1000\n",
      "28709/28709 [==============================] - 15s 510us/step - loss: 0.0201 - acc: 0.9938 - val_loss: 6.4925 - val_acc: 0.3952\n",
      "Epoch 572/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 9s 328us/step - loss: 0.6027 - acc: 0.9331 - val_loss: 5.0567 - val_acc: 0.3910\n",
      "Epoch 573/1000\n",
      "28709/28709 [==============================] - 15s 530us/step - loss: 0.0125 - acc: 0.9966 - val_loss: 6.4886 - val_acc: 0.3984\n",
      "Epoch 574/1000\n",
      "28709/28709 [==============================] - 9s 304us/step - loss: 0.7851 - acc: 0.9138 - val_loss: 5.2192 - val_acc: 0.4013\n",
      "Epoch 575/1000\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 0.0116 - acc: 0.9965 - val_loss: 5.7170 - val_acc: 0.4045\n",
      "Epoch 576/1000\n",
      "28709/28709 [==============================] - 9s 307us/step - loss: 0.2045 - acc: 0.9767 - val_loss: 9.1260 - val_acc: 0.2926\n",
      "Epoch 577/1000\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 0.5056 - acc: 0.9387 - val_loss: 6.0579 - val_acc: 0.3957\n",
      "Epoch 578/1000\n",
      "28709/28709 [==============================] - 9s 326us/step - loss: 0.0098 - acc: 0.9966 - val_loss: 6.3552 - val_acc: 0.3952\n",
      "Epoch 579/1000\n",
      "28709/28709 [==============================] - 14s 499us/step - loss: 0.8681 - acc: 0.9097 - val_loss: 5.9483 - val_acc: 0.3995\n",
      "Epoch 580/1000\n",
      "28709/28709 [==============================] - 11s 387us/step - loss: 0.0088 - acc: 0.9968 - val_loss: 7.2358 - val_acc: 0.3447\n",
      "Epoch 581/1000\n",
      "28709/28709 [==============================] - 12s 429us/step - loss: 0.7873 - acc: 0.9091 - val_loss: 6.1134 - val_acc: 0.3965\n",
      "Epoch 582/1000\n",
      "28709/28709 [==============================] - 12s 432us/step - loss: 0.0279 - acc: 0.9929 - val_loss: 9.2650 - val_acc: 0.3051\n",
      "Epoch 583/1000\n",
      "28709/28709 [==============================] - 11s 371us/step - loss: 0.6594 - acc: 0.9193 - val_loss: 6.0206 - val_acc: 0.3995\n",
      "Epoch 584/1000\n",
      "28709/28709 [==============================] - 15s 535us/step - loss: 0.0098 - acc: 0.9963 - val_loss: 6.1104 - val_acc: 0.4007\n",
      "Epoch 585/1000\n",
      "28709/28709 [==============================] - 9s 328us/step - loss: 1.2091 - acc: 0.8796 - val_loss: 5.3647 - val_acc: 0.3915\n",
      "Epoch 586/1000\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 0.0115 - acc: 0.9966 - val_loss: 6.3102 - val_acc: 0.3968\n",
      "Epoch 587/1000\n",
      "28709/28709 [==============================] - 11s 366us/step - loss: 0.6526 - acc: 0.9316 - val_loss: 5.2109 - val_acc: 0.4014\n",
      "Epoch 588/1000\n",
      "28709/28709 [==============================] - 14s 472us/step - loss: 0.4624 - acc: 0.9536 - val_loss: 5.9774 - val_acc: 0.3621\n",
      "Epoch 589/1000\n",
      "28709/28709 [==============================] - 13s 451us/step - loss: 0.0525 - acc: 0.9867 - val_loss: 5.3396 - val_acc: 0.4035\n",
      "Epoch 590/1000\n",
      "28709/28709 [==============================] - 11s 379us/step - loss: 0.0336 - acc: 0.9913 - val_loss: 9.1892 - val_acc: 0.3244\n",
      "Epoch 591/1000\n",
      "28709/28709 [==============================] - 16s 555us/step - loss: 0.7427 - acc: 0.9199 - val_loss: 6.4201 - val_acc: 0.4000\n",
      "Epoch 592/1000\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.0089 - acc: 0.9967 - val_loss: 6.6156 - val_acc: 0.3919\n",
      "Epoch 593/1000\n",
      "28709/28709 [==============================] - 17s 584us/step - loss: 0.5283 - acc: 0.9434 - val_loss: 5.6334 - val_acc: 0.3926\n",
      "Epoch 594/1000\n",
      "28709/28709 [==============================] - 9s 323us/step - loss: 0.6365 - acc: 0.9285 - val_loss: 5.2563 - val_acc: 0.3908\n",
      "Epoch 595/1000\n",
      "28709/28709 [==============================] - 14s 480us/step - loss: 0.0155 - acc: 0.9956 - val_loss: 5.9399 - val_acc: 0.3999\n",
      "Epoch 596/1000\n",
      "28709/28709 [==============================] - 13s 436us/step - loss: 0.7358 - acc: 0.9230 - val_loss: 5.3884 - val_acc: 0.3997\n",
      "Epoch 597/1000\n",
      "28709/28709 [==============================] - 11s 377us/step - loss: 0.0120 - acc: 0.9964 - val_loss: 5.9688 - val_acc: 0.3970\n",
      "Epoch 598/1000\n",
      "28709/28709 [==============================] - 15s 539us/step - loss: 0.8506 - acc: 0.9143 - val_loss: 5.4001 - val_acc: 0.4032\n",
      "Epoch 599/1000\n",
      "28709/28709 [==============================] - 9s 307us/step - loss: 0.0161 - acc: 0.9951 - val_loss: 6.4112 - val_acc: 0.4052\n",
      "Epoch 600/1000\n",
      "28709/28709 [==============================] - 17s 592us/step - loss: 0.6594 - acc: 0.9278 - val_loss: 5.4670 - val_acc: 0.4049\n",
      "Epoch 601/1000\n",
      "28709/28709 [==============================] - 10s 338us/step - loss: 0.0135 - acc: 0.9959 - val_loss: 5.4877 - val_acc: 0.4055\n",
      "Epoch 602/1000\n",
      "28709/28709 [==============================] - 14s 483us/step - loss: 0.7299 - acc: 0.9239 - val_loss: 5.6215 - val_acc: 0.3841\n",
      "Epoch 603/1000\n",
      "28709/28709 [==============================] - 12s 421us/step - loss: 0.0132 - acc: 0.9962 - val_loss: 5.6068 - val_acc: 0.4002\n",
      "Epoch 604/1000\n",
      "28709/28709 [==============================] - 11s 366us/step - loss: 0.8030 - acc: 0.9223 - val_loss: 5.8267 - val_acc: 0.3922\n",
      "Epoch 605/1000\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 0.0160 - acc: 0.9947 - val_loss: 6.2960 - val_acc: 0.4000\n",
      "Epoch 606/1000\n",
      "28709/28709 [==============================] - 9s 325us/step - loss: 0.6340 - acc: 0.9325 - val_loss: 5.4866 - val_acc: 0.3991\n",
      "Epoch 607/1000\n",
      "28709/28709 [==============================] - 13s 464us/step - loss: 0.0113 - acc: 0.9967 - val_loss: 5.6840 - val_acc: 0.4003\n",
      "Epoch 608/1000\n",
      "28709/28709 [==============================] - 13s 445us/step - loss: 1.0159 - acc: 0.9183 - val_loss: 7.5770 - val_acc: 0.3677\n",
      "Epoch 609/1000\n",
      "28709/28709 [==============================] - 10s 337us/step - loss: 0.1803 - acc: 0.9697 - val_loss: 5.7995 - val_acc: 0.4017\n",
      "Epoch 610/1000\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 0.0109 - acc: 0.9962 - val_loss: 8.4819 - val_acc: 0.3203\n",
      "Epoch 611/1000\n",
      "28709/28709 [==============================] - 9s 318us/step - loss: 0.6680 - acc: 0.9271 - val_loss: 5.7674 - val_acc: 0.3954\n",
      "Epoch 612/1000\n",
      "28709/28709 [==============================] - 14s 492us/step - loss: 0.0077 - acc: 0.9968 - val_loss: 6.9789 - val_acc: 0.3840\n",
      "Epoch 613/1000\n",
      "28709/28709 [==============================] - 13s 452us/step - loss: 0.8467 - acc: 0.9068 - val_loss: 5.6330 - val_acc: 0.4016\n",
      "Epoch 614/1000\n",
      "28709/28709 [==============================] - 10s 357us/step - loss: 0.0088 - acc: 0.9969 - val_loss: 6.7177 - val_acc: 0.3896\n",
      "Epoch 615/1000\n",
      "28709/28709 [==============================] - 17s 608us/step - loss: 0.6744 - acc: 0.9287 - val_loss: 5.5233 - val_acc: 0.4018\n",
      "Epoch 616/1000\n",
      "28709/28709 [==============================] - 10s 363us/step - loss: 0.0081 - acc: 0.9971 - val_loss: 5.8557 - val_acc: 0.3925\n",
      "Epoch 617/1000\n",
      "28709/28709 [==============================] - 14s 480us/step - loss: 0.8350 - acc: 0.9114 - val_loss: 5.6792 - val_acc: 0.3981\n",
      "Epoch 618/1000\n",
      "28709/28709 [==============================] - 15s 516us/step - loss: 0.0087 - acc: 0.9969 - val_loss: 5.9503 - val_acc: 0.4010\n",
      "Epoch 619/1000\n",
      "28709/28709 [==============================] - 11s 376us/step - loss: 1.0679 - acc: 0.9018 - val_loss: 5.7833 - val_acc: 0.4004\n",
      "Epoch 620/1000\n",
      "28709/28709 [==============================] - 16s 544us/step - loss: 0.0082 - acc: 0.9968 - val_loss: 6.4569 - val_acc: 0.4021\n",
      "Epoch 621/1000\n",
      "28709/28709 [==============================] - 12s 418us/step - loss: 0.8183 - acc: 0.9190 - val_loss: 5.8675 - val_acc: 0.4009\n",
      "Epoch 622/1000\n",
      "28709/28709 [==============================] - 13s 456us/step - loss: 0.0108 - acc: 0.9960 - val_loss: 8.2848 - val_acc: 0.3086\n",
      "Epoch 623/1000\n",
      "28709/28709 [==============================] - 19s 655us/step - loss: 0.6282 - acc: 0.9290 - val_loss: 5.6631 - val_acc: 0.4031\n",
      "Epoch 624/1000\n",
      "28709/28709 [==============================] - 12s 411us/step - loss: 0.0085 - acc: 0.9970 - val_loss: 6.1705 - val_acc: 0.3942\n",
      "Epoch 625/1000\n",
      "28709/28709 [==============================] - 15s 513us/step - loss: 0.6965 - acc: 0.9232 - val_loss: 6.4129 - val_acc: 0.3981\n",
      "Epoch 626/1000\n",
      "28709/28709 [==============================] - 16s 573us/step - loss: 0.0079 - acc: 0.9970 - val_loss: 6.4343 - val_acc: 0.3981\n",
      "Epoch 627/1000\n",
      "28709/28709 [==============================] - 10s 354us/step - loss: 0.8037 - acc: 0.9120 - val_loss: 5.7855 - val_acc: 0.4028\n",
      "Epoch 628/1000\n",
      "28709/28709 [==============================] - 17s 592us/step - loss: 0.0093 - acc: 0.9966 - val_loss: 6.1371 - val_acc: 0.4048\n",
      "Epoch 629/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 13s 440us/step - loss: 0.6467 - acc: 0.9297 - val_loss: 6.4820 - val_acc: 0.3992\n",
      "Epoch 630/1000\n",
      "28709/28709 [==============================] - 13s 464us/step - loss: 0.0086 - acc: 0.9967 - val_loss: 6.5712 - val_acc: 0.3956\n",
      "Epoch 631/1000\n",
      "28709/28709 [==============================] - 16s 547us/step - loss: 0.7189 - acc: 0.9195 - val_loss: 5.7480 - val_acc: 0.3825\n",
      "Epoch 632/1000\n",
      "28709/28709 [==============================] - 10s 349us/step - loss: 0.0142 - acc: 0.9957 - val_loss: 5.5983 - val_acc: 0.4018\n",
      "Epoch 633/1000\n",
      "28709/28709 [==============================] - 17s 577us/step - loss: 0.7933 - acc: 0.9225 - val_loss: 6.1470 - val_acc: 0.3919\n",
      "Epoch 634/1000\n",
      "28709/28709 [==============================] - 9s 319us/step - loss: 0.0352 - acc: 0.9901 - val_loss: 5.7337 - val_acc: 0.3977\n",
      "Epoch 635/1000\n",
      "28709/28709 [==============================] - 15s 529us/step - loss: 0.2869 - acc: 0.9696 - val_loss: 8.3036 - val_acc: 0.2913\n",
      "Epoch 636/1000\n",
      "28709/28709 [==============================] - 12s 417us/step - loss: 0.2276 - acc: 0.9652 - val_loss: 5.7878 - val_acc: 0.3968\n",
      "Epoch 637/1000\n",
      "28709/28709 [==============================] - 11s 395us/step - loss: 0.0196 - acc: 0.9948 - val_loss: 10.2780 - val_acc: 0.2501\n",
      "Epoch 638/1000\n",
      "28709/28709 [==============================] - 13s 463us/step - loss: 0.6167 - acc: 0.9314 - val_loss: 6.0132 - val_acc: 0.4004\n",
      "Epoch 639/1000\n",
      "28709/28709 [==============================] - 10s 355us/step - loss: 0.0084 - acc: 0.9970 - val_loss: 6.4914 - val_acc: 0.3783\n",
      "Epoch 640/1000\n",
      "28709/28709 [==============================] - 14s 487us/step - loss: 0.7742 - acc: 0.9213 - val_loss: 5.7809 - val_acc: 0.3999\n",
      "Epoch 641/1000\n",
      "28709/28709 [==============================] - 9s 328us/step - loss: 0.0081 - acc: 0.9972 - val_loss: 6.0218 - val_acc: 0.3957\n",
      "Epoch 642/1000\n",
      "28709/28709 [==============================] - 15s 514us/step - loss: 0.7080 - acc: 0.9252 - val_loss: 5.7663 - val_acc: 0.3949\n",
      "Epoch 643/1000\n",
      "28709/28709 [==============================] - 8s 291us/step - loss: 0.0078 - acc: 0.9970 - val_loss: 5.9460 - val_acc: 0.3995\n",
      "Epoch 644/1000\n",
      "28709/28709 [==============================] - 16s 549us/step - loss: 0.7232 - acc: 0.9218 - val_loss: 5.8110 - val_acc: 0.3939\n",
      "Epoch 645/1000\n",
      "28709/28709 [==============================] - 8s 278us/step - loss: 0.0084 - acc: 0.9970 - val_loss: 6.4865 - val_acc: 0.3974\n",
      "Epoch 646/1000\n",
      "28709/28709 [==============================] - 16s 549us/step - loss: 0.7148 - acc: 0.9236 - val_loss: 5.6092 - val_acc: 0.4024\n",
      "Epoch 647/1000\n",
      "28709/28709 [==============================] - 8s 290us/step - loss: 0.0085 - acc: 0.9972 - val_loss: 5.9117 - val_acc: 0.4009\n",
      "Epoch 648/1000\n",
      "28709/28709 [==============================] - 16s 544us/step - loss: 0.7052 - acc: 0.9249 - val_loss: 5.6922 - val_acc: 0.3839\n",
      "Epoch 649/1000\n",
      "28709/28709 [==============================] - 8s 290us/step - loss: 0.0145 - acc: 0.9949 - val_loss: 6.3677 - val_acc: 0.3963\n",
      "Epoch 650/1000\n",
      "28709/28709 [==============================] - 14s 488us/step - loss: 0.7397 - acc: 0.9259 - val_loss: 5.7449 - val_acc: 0.3816\n",
      "Epoch 651/1000\n",
      "28709/28709 [==============================] - 10s 351us/step - loss: 0.0142 - acc: 0.9953 - val_loss: 5.7978 - val_acc: 0.4009\n",
      "Epoch 652/1000\n",
      "28709/28709 [==============================] - 12s 417us/step - loss: 0.9538 - acc: 0.9228 - val_loss: 6.2076 - val_acc: 0.3853\n",
      "Epoch 653/1000\n",
      "28709/28709 [==============================] - 12s 413us/step - loss: 0.0472 - acc: 0.9865 - val_loss: 5.9040 - val_acc: 0.4011\n",
      "Epoch 654/1000\n",
      "28709/28709 [==============================] - 11s 371us/step - loss: 0.0555 - acc: 0.9900 - val_loss: 7.7885 - val_acc: 0.3538\n",
      "Epoch 655/1000\n",
      "28709/28709 [==============================] - 13s 468us/step - loss: 0.1799 - acc: 0.9729 - val_loss: 5.8888 - val_acc: 0.3960\n",
      "Epoch 656/1000\n",
      "28709/28709 [==============================] - 9s 307us/step - loss: 0.0261 - acc: 0.9935 - val_loss: 6.7502 - val_acc: 0.3731\n",
      "Epoch 657/1000\n",
      "28709/28709 [==============================] - 16s 540us/step - loss: 0.2611 - acc: 0.9565 - val_loss: 5.8021 - val_acc: 0.4025\n",
      "Epoch 658/1000\n",
      "28709/28709 [==============================] - 8s 274us/step - loss: 0.4184 - acc: 0.9567 - val_loss: 8.4944 - val_acc: 0.3331\n",
      "Epoch 659/1000\n",
      "28709/28709 [==============================] - 15s 531us/step - loss: 0.2182 - acc: 0.9712 - val_loss: 6.3074 - val_acc: 0.3996\n",
      "Epoch 660/1000\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.0084 - acc: 0.9964 - val_loss: 7.0249 - val_acc: 0.3641\n",
      "Epoch 661/1000\n",
      "28709/28709 [==============================] - 13s 462us/step - loss: 0.8429 - acc: 0.9138 - val_loss: 6.7845 - val_acc: 0.3963\n",
      "Epoch 662/1000\n",
      "28709/28709 [==============================] - 10s 358us/step - loss: 0.0089 - acc: 0.9966 - val_loss: 6.9265 - val_acc: 0.3869\n",
      "Epoch 663/1000\n",
      "28709/28709 [==============================] - 12s 407us/step - loss: 0.7175 - acc: 0.9298 - val_loss: 6.3159 - val_acc: 0.3956\n",
      "Epoch 664/1000\n",
      "28709/28709 [==============================] - 12s 429us/step - loss: 0.1716 - acc: 0.9807 - val_loss: 9.3567 - val_acc: 0.2704\n",
      "Epoch 665/1000\n",
      "28709/28709 [==============================] - 9s 322us/step - loss: 0.3788 - acc: 0.9542 - val_loss: 6.7373 - val_acc: 0.3847\n",
      "Epoch 666/1000\n",
      "28709/28709 [==============================] - 15s 512us/step - loss: 0.4068 - acc: 0.9615 - val_loss: 7.6343 - val_acc: 0.3428\n",
      "Epoch 667/1000\n",
      "28709/28709 [==============================] - 8s 296us/step - loss: 0.2299 - acc: 0.9633 - val_loss: 6.5880 - val_acc: 0.3988\n",
      "Epoch 668/1000\n",
      "28709/28709 [==============================] - 13s 444us/step - loss: 0.6818 - acc: 0.9272 - val_loss: 5.5831 - val_acc: 0.3924\n",
      "Epoch 669/1000\n",
      "28709/28709 [==============================] - 11s 374us/step - loss: 0.0099 - acc: 0.9972 - val_loss: 5.7914 - val_acc: 0.3988\n",
      "Epoch 670/1000\n",
      "28709/28709 [==============================] - 10s 365us/step - loss: 0.0413 - acc: 0.9919 - val_loss: 8.5637 - val_acc: 0.3479\n",
      "Epoch 671/1000\n",
      "28709/28709 [==============================] - 13s 458us/step - loss: 0.4542 - acc: 0.9442 - val_loss: 5.9593 - val_acc: 0.3872\n",
      "Epoch 672/1000\n",
      "28709/28709 [==============================] - 8s 292us/step - loss: 0.0174 - acc: 0.9950 - val_loss: 8.1677 - val_acc: 0.3631\n",
      "Epoch 673/1000\n",
      "28709/28709 [==============================] - 16s 553us/step - loss: 0.3339 - acc: 0.9592 - val_loss: 6.6843 - val_acc: 0.4063\n",
      "Epoch 674/1000\n",
      "28709/28709 [==============================] - 8s 268us/step - loss: 0.1497 - acc: 0.9825 - val_loss: 9.9779 - val_acc: 0.2514\n",
      "Epoch 675/1000\n",
      "28709/28709 [==============================] - 13s 458us/step - loss: 0.3691 - acc: 0.9544 - val_loss: 6.6450 - val_acc: 0.3970\n",
      "Epoch 676/1000\n",
      "28709/28709 [==============================] - 10s 354us/step - loss: 0.0084 - acc: 0.9968 - val_loss: 6.5803 - val_acc: 0.4035\n",
      "Epoch 677/1000\n",
      "28709/28709 [==============================] - 11s 399us/step - loss: 1.0154 - acc: 0.9028 - val_loss: 7.0060 - val_acc: 0.3894\n",
      "Epoch 678/1000\n",
      "28709/28709 [==============================] - 11s 400us/step - loss: 0.0104 - acc: 0.9963 - val_loss: 6.5971 - val_acc: 0.4045\n",
      "Epoch 679/1000\n",
      "28709/28709 [==============================] - 10s 340us/step - loss: 0.6620 - acc: 0.9280 - val_loss: 5.7332 - val_acc: 0.4041\n",
      "Epoch 680/1000\n",
      "28709/28709 [==============================] - 13s 467us/step - loss: 0.0074 - acc: 0.9972 - val_loss: 6.3679 - val_acc: 0.4037\n",
      "Epoch 681/1000\n",
      "28709/28709 [==============================] - 8s 285us/step - loss: 0.8979 - acc: 0.9170 - val_loss: 5.8009 - val_acc: 0.4024\n",
      "Epoch 682/1000\n",
      "28709/28709 [==============================] - 14s 500us/step - loss: 0.0095 - acc: 0.9970 - val_loss: 6.0671 - val_acc: 0.3853\n",
      "Epoch 683/1000\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.0125 - acc: 0.9961 - val_loss: 6.1040 - val_acc: 0.3995\n",
      "Epoch 684/1000\n",
      "28709/28709 [==============================] - 12s 424us/step - loss: 0.8075 - acc: 0.9131 - val_loss: 5.9319 - val_acc: 0.3997\n",
      "Epoch 685/1000\n",
      "28709/28709 [==============================] - 11s 376us/step - loss: 0.0076 - acc: 0.9970 - val_loss: 6.7149 - val_acc: 0.4031\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 10s 355us/step - loss: 0.8120 - acc: 0.9155 - val_loss: 5.8738 - val_acc: 0.3993\n",
      "Epoch 687/1000\n",
      "28709/28709 [==============================] - 13s 460us/step - loss: 0.0077 - acc: 0.9968 - val_loss: 6.6378 - val_acc: 0.3991\n",
      "Epoch 688/1000\n",
      "28709/28709 [==============================] - 8s 277us/step - loss: 0.6438 - acc: 0.9318 - val_loss: 5.8321 - val_acc: 0.3974\n",
      "Epoch 689/1000\n",
      "28709/28709 [==============================] - 14s 472us/step - loss: 0.0080 - acc: 0.9969 - val_loss: 6.0111 - val_acc: 0.3988\n",
      "Epoch 690/1000\n",
      "28709/28709 [==============================] - 10s 334us/step - loss: 0.6442 - acc: 0.9333 - val_loss: 5.7878 - val_acc: 0.3967\n",
      "Epoch 691/1000\n",
      "28709/28709 [==============================] - 11s 375us/step - loss: 0.0077 - acc: 0.9974 - val_loss: 5.8580 - val_acc: 0.4021\n",
      "Epoch 692/1000\n",
      "28709/28709 [==============================] - 13s 457us/step - loss: 0.8934 - acc: 0.9125 - val_loss: 5.9398 - val_acc: 0.3981\n",
      "Epoch 693/1000\n",
      "28709/28709 [==============================] - 8s 278us/step - loss: 0.0109 - acc: 0.9966 - val_loss: 5.9807 - val_acc: 0.4003\n",
      "Epoch 694/1000\n",
      "28709/28709 [==============================] - 14s 482us/step - loss: 0.6375 - acc: 0.9351 - val_loss: 5.8520 - val_acc: 0.3989\n",
      "Epoch 695/1000\n",
      "28709/28709 [==============================] - 10s 356us/step - loss: 0.0101 - acc: 0.9967 - val_loss: 6.2501 - val_acc: 0.4049\n",
      "Epoch 696/1000\n",
      "28709/28709 [==============================] - 11s 382us/step - loss: 0.0089 - acc: 0.9966 - val_loss: 6.4406 - val_acc: 0.4045\n",
      "Epoch 697/1000\n",
      "28709/28709 [==============================] - 15s 518us/step - loss: 0.9433 - acc: 0.9099 - val_loss: 5.9825 - val_acc: 0.3981\n",
      "Epoch 698/1000\n",
      "28709/28709 [==============================] - 8s 264us/step - loss: 0.0078 - acc: 0.9972 - val_loss: 6.1212 - val_acc: 0.4000\n",
      "Epoch 699/1000\n",
      "28709/28709 [==============================] - 13s 463us/step - loss: 0.5201 - acc: 0.9384 - val_loss: 5.8955 - val_acc: 0.4007\n",
      "Epoch 700/1000\n",
      "28709/28709 [==============================] - 10s 356us/step - loss: 0.0081 - acc: 0.9971 - val_loss: 5.9843 - val_acc: 0.4016\n",
      "Epoch 701/1000\n",
      "28709/28709 [==============================] - 11s 375us/step - loss: 0.6446 - acc: 0.9306 - val_loss: 5.9306 - val_acc: 0.4011\n",
      "Epoch 702/1000\n",
      "28709/28709 [==============================] - 13s 452us/step - loss: 0.0078 - acc: 0.9971 - val_loss: 6.0623 - val_acc: 0.4016\n",
      "Epoch 703/1000\n",
      "28709/28709 [==============================] - 8s 269us/step - loss: 0.6706 - acc: 0.9324 - val_loss: 5.9102 - val_acc: 0.3924\n",
      "Epoch 704/1000\n",
      "28709/28709 [==============================] - 15s 523us/step - loss: 0.0093 - acc: 0.9970 - val_loss: 6.0383 - val_acc: 0.4004\n",
      "Epoch 705/1000\n",
      "28709/28709 [==============================] - 8s 276us/step - loss: 0.7182 - acc: 0.9332 - val_loss: 6.6737 - val_acc: 0.3612\n",
      "Epoch 706/1000\n",
      "28709/28709 [==============================] - 12s 427us/step - loss: 0.0438 - acc: 0.9886 - val_loss: 6.7785 - val_acc: 0.4078\n",
      "Epoch 707/1000\n",
      "28709/28709 [==============================] - 11s 392us/step - loss: 0.0083 - acc: 0.9968 - val_loss: 6.5526 - val_acc: 0.3938\n",
      "Epoch 708/1000\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.6894 - acc: 0.9305 - val_loss: 6.0775 - val_acc: 0.3996\n",
      "Epoch 709/1000\n",
      "28709/28709 [==============================] - 14s 499us/step - loss: 0.0077 - acc: 0.9970 - val_loss: 6.5145 - val_acc: 0.3939\n",
      "Epoch 710/1000\n",
      "28709/28709 [==============================] - 8s 292us/step - loss: 0.5242 - acc: 0.9457 - val_loss: 6.0141 - val_acc: 0.4030\n",
      "Epoch 711/1000\n",
      "28709/28709 [==============================] - 12s 406us/step - loss: 0.0078 - acc: 0.9970 - val_loss: 6.3572 - val_acc: 0.3961\n",
      "Epoch 712/1000\n",
      "28709/28709 [==============================] - 11s 386us/step - loss: 0.6865 - acc: 0.9273 - val_loss: 6.0802 - val_acc: 0.4031\n",
      "Epoch 713/1000\n",
      "28709/28709 [==============================] - 9s 312us/step - loss: 0.0082 - acc: 0.9969 - val_loss: 6.3316 - val_acc: 0.3992\n",
      "Epoch 714/1000\n",
      "28709/28709 [==============================] - 14s 498us/step - loss: 0.5079 - acc: 0.9378 - val_loss: 5.9299 - val_acc: 0.3997\n",
      "Epoch 715/1000\n",
      "28709/28709 [==============================] - 8s 270us/step - loss: 0.0071 - acc: 0.9974 - val_loss: 6.0521 - val_acc: 0.3992\n",
      "Epoch 716/1000\n",
      "28709/28709 [==============================] - 12s 431us/step - loss: 0.8206 - acc: 0.9301 - val_loss: 7.2895 - val_acc: 0.3762\n",
      "Epoch 717/1000\n",
      "28709/28709 [==============================] - 11s 381us/step - loss: 0.0737 - acc: 0.9856 - val_loss: 6.1753 - val_acc: 0.4000\n",
      "Epoch 718/1000\n",
      "28709/28709 [==============================] - 9s 307us/step - loss: 0.1823 - acc: 0.9785 - val_loss: 8.5699 - val_acc: 0.3453\n",
      "Epoch 719/1000\n",
      "28709/28709 [==============================] - 14s 497us/step - loss: 0.3580 - acc: 0.9547 - val_loss: 6.1358 - val_acc: 0.4018\n",
      "Epoch 720/1000\n",
      "28709/28709 [==============================] - 7s 248us/step - loss: 0.0162 - acc: 0.9956 - val_loss: 8.5503 - val_acc: 0.3060\n",
      "Epoch 721/1000\n",
      "28709/28709 [==============================] - 13s 463us/step - loss: 0.3790 - acc: 0.9540 - val_loss: 6.0874 - val_acc: 0.4011\n",
      "Epoch 722/1000\n",
      "28709/28709 [==============================] - 10s 346us/step - loss: 0.0071 - acc: 0.9971 - val_loss: 6.4987 - val_acc: 0.3992\n",
      "Epoch 723/1000\n",
      "28709/28709 [==============================] - 9s 329us/step - loss: 0.6356 - acc: 0.9310 - val_loss: 6.0874 - val_acc: 0.4018\n",
      "Epoch 724/1000\n",
      "28709/28709 [==============================] - 14s 485us/step - loss: 0.0072 - acc: 0.9969 - val_loss: 6.1405 - val_acc: 0.4030\n",
      "Epoch 725/1000\n",
      "28709/28709 [==============================] - 7s 250us/step - loss: 0.6337 - acc: 0.9333 - val_loss: 5.9337 - val_acc: 0.3988\n",
      "Epoch 726/1000\n",
      "28709/28709 [==============================] - 13s 461us/step - loss: 0.0074 - acc: 0.9972 - val_loss: 6.2170 - val_acc: 0.3996\n",
      "Epoch 727/1000\n",
      "28709/28709 [==============================] - 10s 345us/step - loss: 0.9487 - acc: 0.9104 - val_loss: 6.1610 - val_acc: 0.3991\n",
      "Epoch 728/1000\n",
      "28709/28709 [==============================] - 10s 340us/step - loss: 0.0138 - acc: 0.9954 - val_loss: 6.6658 - val_acc: 0.4009\n",
      "Epoch 729/1000\n",
      "28709/28709 [==============================] - 13s 465us/step - loss: 0.0563 - acc: 0.9890 - val_loss: 9.0286 - val_acc: 0.3237\n",
      "Epoch 730/1000\n",
      "28709/28709 [==============================] - 8s 264us/step - loss: 0.6876 - acc: 0.9327 - val_loss: 6.6491 - val_acc: 0.3971\n",
      "Epoch 731/1000\n",
      "28709/28709 [==============================] - 12s 429us/step - loss: 0.0084 - acc: 0.9965 - val_loss: 6.7436 - val_acc: 0.3950\n",
      "Epoch 732/1000\n",
      "28709/28709 [==============================] - 11s 372us/step - loss: 0.5911 - acc: 0.9323 - val_loss: 5.9702 - val_acc: 0.4002\n",
      "Epoch 733/1000\n",
      "28709/28709 [==============================] - 9s 322us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 6.3815 - val_acc: 0.4071\n",
      "Epoch 734/1000\n",
      "28709/28709 [==============================] - 14s 477us/step - loss: 0.6398 - acc: 0.9337 - val_loss: 6.0897 - val_acc: 0.3921\n",
      "Epoch 735/1000\n",
      "28709/28709 [==============================] - 8s 263us/step - loss: 0.0076 - acc: 0.9970 - val_loss: 6.1038 - val_acc: 0.3995\n",
      "Epoch 736/1000\n",
      "28709/28709 [==============================] - 12s 419us/step - loss: 0.5986 - acc: 0.9348 - val_loss: 6.0848 - val_acc: 0.3988\n",
      "Epoch 737/1000\n",
      "28709/28709 [==============================] - 11s 377us/step - loss: 0.0070 - acc: 0.9973 - val_loss: 6.1671 - val_acc: 0.4014\n",
      "Epoch 738/1000\n",
      "28709/28709 [==============================] - 9s 313us/step - loss: 0.8276 - acc: 0.9218 - val_loss: 6.2497 - val_acc: 0.4098\n",
      "Epoch 739/1000\n",
      "28709/28709 [==============================] - 14s 489us/step - loss: 0.0106 - acc: 0.9961 - val_loss: 6.4430 - val_acc: 0.4064\n",
      "Epoch 740/1000\n",
      "28709/28709 [==============================] - 7s 249us/step - loss: 0.4219 - acc: 0.9599 - val_loss: 7.3846 - val_acc: 0.3653\n",
      "Epoch 741/1000\n",
      "28709/28709 [==============================] - 13s 442us/step - loss: 0.0826 - acc: 0.9823 - val_loss: 6.2271 - val_acc: 0.4016\n",
      "Epoch 742/1000\n",
      "28709/28709 [==============================] - 10s 345us/step - loss: 0.0078 - acc: 0.9969 - val_loss: 6.5919 - val_acc: 0.4023\n",
      "Epoch 743/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 10s 341us/step - loss: 0.8176 - acc: 0.9185 - val_loss: 6.5319 - val_acc: 0.4032\n",
      "Epoch 744/1000\n",
      "28709/28709 [==============================] - 13s 467us/step - loss: 0.0068 - acc: 0.9971 - val_loss: 6.4366 - val_acc: 0.3940\n",
      "Epoch 745/1000\n",
      "28709/28709 [==============================] - 7s 235us/step - loss: 0.8093 - acc: 0.9202 - val_loss: 6.1852 - val_acc: 0.3977\n",
      "Epoch 746/1000\n",
      "28709/28709 [==============================] - 14s 475us/step - loss: 0.0074 - acc: 0.9969 - val_loss: 6.7284 - val_acc: 0.4021\n",
      "Epoch 747/1000\n",
      "28709/28709 [==============================] - 10s 331us/step - loss: 0.7581 - acc: 0.9241 - val_loss: 6.0455 - val_acc: 0.4069\n",
      "Epoch 748/1000\n",
      "28709/28709 [==============================] - 10s 355us/step - loss: 0.0071 - acc: 0.9972 - val_loss: 6.1637 - val_acc: 0.4041\n",
      "Epoch 749/1000\n",
      "28709/28709 [==============================] - 12s 433us/step - loss: 0.7652 - acc: 0.9265 - val_loss: 6.1492 - val_acc: 0.4045\n",
      "Epoch 750/1000\n",
      "28709/28709 [==============================] - 7s 254us/step - loss: 0.0087 - acc: 0.9966 - val_loss: 6.7641 - val_acc: 0.4021\n",
      "Epoch 751/1000\n",
      "28709/28709 [==============================] - 14s 479us/step - loss: 0.8380 - acc: 0.9275 - val_loss: 6.7093 - val_acc: 0.3839\n",
      "Epoch 752/1000\n",
      "28709/28709 [==============================] - 11s 372us/step - loss: 0.0296 - acc: 0.9916 - val_loss: 6.6508 - val_acc: 0.3975\n",
      "Epoch 753/1000\n",
      "28709/28709 [==============================] - 11s 396us/step - loss: 0.6132 - acc: 0.9442 - val_loss: 6.8831 - val_acc: 0.3726\n",
      "Epoch 754/1000\n",
      "28709/28709 [==============================] - 14s 481us/step - loss: 0.0551 - acc: 0.9855 - val_loss: 6.2894 - val_acc: 0.3999\n",
      "Epoch 755/1000\n",
      "28709/28709 [==============================] - 8s 290us/step - loss: 0.0080 - acc: 0.9970 - val_loss: 6.4853 - val_acc: 0.3896\n",
      "Epoch 756/1000\n",
      "28709/28709 [==============================] - 12s 416us/step - loss: 1.4625 - acc: 0.8733 - val_loss: 6.5768 - val_acc: 0.4010\n",
      "Epoch 757/1000\n",
      "28709/28709 [==============================] - 12s 431us/step - loss: 0.0086 - acc: 0.9968 - val_loss: 6.8227 - val_acc: 0.3975\n",
      "Epoch 758/1000\n",
      "28709/28709 [==============================] - 8s 271us/step - loss: 0.7092 - acc: 0.9254 - val_loss: 6.2148 - val_acc: 0.3981\n",
      "Epoch 759/1000\n",
      "28709/28709 [==============================] - 14s 499us/step - loss: 0.0072 - acc: 0.9970 - val_loss: 6.6452 - val_acc: 0.3963\n",
      "Epoch 760/1000\n",
      "28709/28709 [==============================] - 10s 350us/step - loss: 1.0051 - acc: 0.9105 - val_loss: 6.3969 - val_acc: 0.3952\n",
      "Epoch 761/1000\n",
      "28709/28709 [==============================] - 10s 347us/step - loss: 0.0094 - acc: 0.9969 - val_loss: 6.3798 - val_acc: 0.4011\n",
      "Epoch 762/1000\n",
      "28709/28709 [==============================] - 14s 495us/step - loss: 0.7253 - acc: 0.9296 - val_loss: 6.1585 - val_acc: 0.4037\n",
      "Epoch 763/1000\n",
      "28709/28709 [==============================] - 8s 279us/step - loss: 0.0082 - acc: 0.9968 - val_loss: 6.2335 - val_acc: 0.4028\n",
      "Epoch 764/1000\n",
      "28709/28709 [==============================] - 12s 420us/step - loss: 0.2119 - acc: 0.9754 - val_loss: 9.4409 - val_acc: 0.3005\n",
      "Epoch 765/1000\n",
      "28709/28709 [==============================] - 13s 439us/step - loss: 0.3361 - acc: 0.9591 - val_loss: 6.3035 - val_acc: 0.4048\n",
      "Epoch 766/1000\n",
      "28709/28709 [==============================] - 9s 318us/step - loss: 0.0863 - acc: 0.9887 - val_loss: 8.3004 - val_acc: 0.3492\n",
      "Epoch 767/1000\n",
      "28709/28709 [==============================] - 15s 506us/step - loss: 0.2307 - acc: 0.9677 - val_loss: 6.3935 - val_acc: 0.4013\n",
      "Epoch 768/1000\n",
      "28709/28709 [==============================] - 11s 386us/step - loss: 0.5190 - acc: 0.9419 - val_loss: 6.1240 - val_acc: 0.4048\n",
      "Epoch 769/1000\n",
      "28709/28709 [==============================] - 10s 343us/step - loss: 0.0077 - acc: 0.9971 - val_loss: 6.6205 - val_acc: 0.4011\n",
      "Epoch 770/1000\n",
      "28709/28709 [==============================] - 15s 531us/step - loss: 0.6530 - acc: 0.9330 - val_loss: 6.0860 - val_acc: 0.3986\n",
      "Epoch 771/1000\n",
      "28709/28709 [==============================] - 10s 332us/step - loss: 0.0083 - acc: 0.9970 - val_loss: 6.1270 - val_acc: 0.4011\n",
      "Epoch 772/1000\n",
      "28709/28709 [==============================] - 12s 409us/step - loss: 0.4532 - acc: 0.9596 - val_loss: 9.5580 - val_acc: 0.3093\n",
      "Epoch 773/1000\n",
      "28709/28709 [==============================] - 14s 484us/step - loss: 0.5110 - acc: 0.9495 - val_loss: 6.3512 - val_acc: 0.4006\n",
      "Epoch 774/1000\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.0083 - acc: 0.9970 - val_loss: 6.4008 - val_acc: 0.3992\n",
      "Epoch 775/1000\n",
      "28709/28709 [==============================] - 13s 453us/step - loss: 0.6260 - acc: 0.9343 - val_loss: 6.2297 - val_acc: 0.4018\n",
      "Epoch 776/1000\n",
      "28709/28709 [==============================] - 13s 453us/step - loss: 0.0065 - acc: 0.9972 - val_loss: 6.6201 - val_acc: 0.3950\n",
      "Epoch 777/1000\n",
      "28709/28709 [==============================] - 8s 291us/step - loss: 0.5461 - acc: 0.9411 - val_loss: 6.2894 - val_acc: 0.4030\n",
      "Epoch 778/1000\n",
      "28709/28709 [==============================] - 14s 503us/step - loss: 0.0082 - acc: 0.9970 - val_loss: 6.3777 - val_acc: 0.4011\n",
      "Epoch 779/1000\n",
      "28709/28709 [==============================] - 12s 403us/step - loss: 0.6924 - acc: 0.9305 - val_loss: 6.2600 - val_acc: 0.4030\n",
      "Epoch 780/1000\n",
      "28709/28709 [==============================] - 9s 330us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 6.5222 - val_acc: 0.4023\n",
      "Epoch 781/1000\n",
      "28709/28709 [==============================] - 14s 498us/step - loss: 0.6129 - acc: 0.9343 - val_loss: 6.2309 - val_acc: 0.3979\n",
      "Epoch 782/1000\n",
      "28709/28709 [==============================] - 11s 398us/step - loss: 0.0073 - acc: 0.9971 - val_loss: 6.2603 - val_acc: 0.3993\n",
      "Epoch 783/1000\n",
      "28709/28709 [==============================] - 10s 338us/step - loss: 0.5256 - acc: 0.9423 - val_loss: 6.2420 - val_acc: 0.4070\n",
      "Epoch 784/1000\n",
      "28709/28709 [==============================] - 15s 521us/step - loss: 0.0101 - acc: 0.9967 - val_loss: 6.2641 - val_acc: 0.4028\n",
      "Epoch 785/1000\n",
      "28709/28709 [==============================] - 10s 342us/step - loss: 0.0074 - acc: 0.9970 - val_loss: 6.4010 - val_acc: 0.4049\n",
      "Epoch 786/1000\n",
      "28709/28709 [==============================] - 11s 399us/step - loss: 0.6770 - acc: 0.9298 - val_loss: 6.2722 - val_acc: 0.3997\n",
      "Epoch 787/1000\n",
      "28709/28709 [==============================] - 15s 522us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 6.4832 - val_acc: 0.3982\n",
      "Epoch 788/1000\n",
      "28709/28709 [==============================] - 9s 304us/step - loss: 1.6353 - acc: 0.8661 - val_loss: 6.3702 - val_acc: 0.4013\n",
      "Epoch 789/1000\n",
      "28709/28709 [==============================] - 12s 425us/step - loss: 0.0091 - acc: 0.9967 - val_loss: 6.4091 - val_acc: 0.3995\n",
      "Epoch 790/1000\n",
      "28709/28709 [==============================] - 14s 503us/step - loss: 0.0079 - acc: 0.9969 - val_loss: 6.5120 - val_acc: 0.3986\n",
      "Epoch 791/1000\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.6683 - acc: 0.9279 - val_loss: 6.2352 - val_acc: 0.4000\n",
      "Epoch 792/1000\n",
      "28709/28709 [==============================] - 13s 455us/step - loss: 0.0071 - acc: 0.9968 - val_loss: 6.3347 - val_acc: 0.3952\n",
      "Epoch 793/1000\n",
      "28709/28709 [==============================] - 14s 476us/step - loss: 0.5448 - acc: 0.9347 - val_loss: 6.1958 - val_acc: 0.4002\n",
      "Epoch 794/1000\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.0077 - acc: 0.9968 - val_loss: 6.2964 - val_acc: 0.4007\n",
      "Epoch 795/1000\n",
      "28709/28709 [==============================] - 14s 478us/step - loss: 0.5073 - acc: 0.9425 - val_loss: 6.1382 - val_acc: 0.4002\n",
      "Epoch 796/1000\n",
      "28709/28709 [==============================] - 12s 423us/step - loss: 0.0072 - acc: 0.9972 - val_loss: 6.2658 - val_acc: 0.3997\n",
      "Epoch 797/1000\n",
      "28709/28709 [==============================] - 9s 329us/step - loss: 0.6908 - acc: 0.9317 - val_loss: 6.3603 - val_acc: 0.3993\n",
      "Epoch 798/1000\n",
      "28709/28709 [==============================] - 16s 574us/step - loss: 0.0090 - acc: 0.9968 - val_loss: 6.3665 - val_acc: 0.3993\n",
      "Epoch 799/1000\n",
      "28709/28709 [==============================] - 13s 443us/step - loss: 0.0202 - acc: 0.9945 - val_loss: 9.7883 - val_acc: 0.3156\n",
      "Epoch 800/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 9s 321us/step - loss: 0.7411 - acc: 0.9289 - val_loss: 6.5346 - val_acc: 0.3993\n",
      "Epoch 801/1000\n",
      "28709/28709 [==============================] - 15s 515us/step - loss: 0.0071 - acc: 0.9974 - val_loss: 6.9501 - val_acc: 0.4059\n",
      "Epoch 802/1000\n",
      "28709/28709 [==============================] - 9s 323us/step - loss: 1.1856 - acc: 0.8970 - val_loss: 6.5814 - val_acc: 0.4020\n",
      "Epoch 803/1000\n",
      "28709/28709 [==============================] - 11s 386us/step - loss: 0.0081 - acc: 0.9969 - val_loss: 6.8209 - val_acc: 0.3981\n",
      "Epoch 804/1000\n",
      "28709/28709 [==============================] - 15s 512us/step - loss: 0.5883 - acc: 0.9386 - val_loss: 6.4465 - val_acc: 0.4006\n",
      "Epoch 805/1000\n",
      "28709/28709 [==============================] - 10s 353us/step - loss: 0.0076 - acc: 0.9969 - val_loss: 6.7149 - val_acc: 0.3988\n",
      "Epoch 806/1000\n",
      "28709/28709 [==============================] - 12s 405us/step - loss: 0.4153 - acc: 0.9469 - val_loss: 6.2169 - val_acc: 0.4024\n",
      "Epoch 807/1000\n",
      "28709/28709 [==============================] - 15s 523us/step - loss: 0.0069 - acc: 0.9972 - val_loss: 6.2765 - val_acc: 0.4010\n",
      "Epoch 808/1000\n",
      "28709/28709 [==============================] - 8s 273us/step - loss: 0.5623 - acc: 0.9445 - val_loss: 6.5895 - val_acc: 0.4007\n",
      "Epoch 809/1000\n",
      "28709/28709 [==============================] - 13s 453us/step - loss: 0.0083 - acc: 0.9966 - val_loss: 6.5683 - val_acc: 0.4098\n",
      "Epoch 810/1000\n",
      "28709/28709 [==============================] - 12s 419us/step - loss: 0.5129 - acc: 0.9407 - val_loss: 6.0393 - val_acc: 0.3979\n",
      "Epoch 811/1000\n",
      "28709/28709 [==============================] - 9s 309us/step - loss: 0.0076 - acc: 0.9970 - val_loss: 6.2613 - val_acc: 0.3894\n",
      "Epoch 812/1000\n",
      "28709/28709 [==============================] - 15s 537us/step - loss: 0.0291 - acc: 0.9925 - val_loss: 9.7697 - val_acc: 0.2841\n",
      "Epoch 813/1000\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.4844 - acc: 0.9475 - val_loss: 6.6936 - val_acc: 0.3964\n",
      "Epoch 814/1000\n",
      "28709/28709 [==============================] - 11s 399us/step - loss: 0.0077 - acc: 0.9968 - val_loss: 6.5936 - val_acc: 0.4032\n",
      "Epoch 815/1000\n",
      "28709/28709 [==============================] - 14s 473us/step - loss: 0.4886 - acc: 0.9429 - val_loss: 6.3008 - val_acc: 0.3924\n",
      "Epoch 816/1000\n",
      "28709/28709 [==============================] - 8s 279us/step - loss: 0.0082 - acc: 0.9971 - val_loss: 6.4664 - val_acc: 0.3943\n",
      "Epoch 817/1000\n",
      "28709/28709 [==============================] - 15s 509us/step - loss: 0.4283 - acc: 0.9471 - val_loss: 6.1025 - val_acc: 0.4048\n",
      "Epoch 818/1000\n",
      "28709/28709 [==============================] - 10s 343us/step - loss: 0.0068 - acc: 0.9972 - val_loss: 6.5953 - val_acc: 0.4003\n",
      "Epoch 819/1000\n",
      "28709/28709 [==============================] - 11s 384us/step - loss: 0.7151 - acc: 0.9269 - val_loss: 6.2716 - val_acc: 0.3978\n",
      "Epoch 820/1000\n",
      "28709/28709 [==============================] - 15s 516us/step - loss: 0.0075 - acc: 0.9969 - val_loss: 6.4174 - val_acc: 0.3979\n",
      "Epoch 821/1000\n",
      "28709/28709 [==============================] - 8s 279us/step - loss: 0.7485 - acc: 0.9288 - val_loss: 6.3745 - val_acc: 0.3988\n",
      "Epoch 822/1000\n",
      "28709/28709 [==============================] - 13s 457us/step - loss: 0.0079 - acc: 0.9970 - val_loss: 6.4006 - val_acc: 0.4030\n",
      "Epoch 823/1000\n",
      "28709/28709 [==============================] - 12s 427us/step - loss: 0.7300 - acc: 0.9304 - val_loss: 6.3661 - val_acc: 0.3979\n",
      "Epoch 824/1000\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 6.4043 - val_acc: 0.4000\n",
      "Epoch 825/1000\n",
      "28709/28709 [==============================] - 15s 529us/step - loss: 0.6185 - acc: 0.9366 - val_loss: 6.2233 - val_acc: 0.4021\n",
      "Epoch 826/1000\n",
      "28709/28709 [==============================] - 9s 310us/step - loss: 0.0067 - acc: 0.9972 - val_loss: 6.4140 - val_acc: 0.4006\n",
      "Epoch 827/1000\n",
      "28709/28709 [==============================] - 12s 413us/step - loss: 0.5849 - acc: 0.9401 - val_loss: 6.3090 - val_acc: 0.3963\n",
      "Epoch 828/1000\n",
      "28709/28709 [==============================] - 13s 459us/step - loss: 0.0080 - acc: 0.9971 - val_loss: 6.3247 - val_acc: 0.4042\n",
      "Epoch 829/1000\n",
      "28709/28709 [==============================] - 8s 282us/step - loss: 0.4171 - acc: 0.9600 - val_loss: 7.5930 - val_acc: 0.3620\n",
      "Epoch 830/1000\n",
      "28709/28709 [==============================] - 14s 490us/step - loss: 0.0879 - acc: 0.9833 - val_loss: 6.8938 - val_acc: 0.4018\n",
      "Epoch 831/1000\n",
      "28709/28709 [==============================] - 11s 390us/step - loss: 0.3885 - acc: 0.9526 - val_loss: 6.2014 - val_acc: 0.3945\n",
      "Epoch 832/1000\n",
      "28709/28709 [==============================] - 10s 332us/step - loss: 0.0073 - acc: 0.9970 - val_loss: 6.6579 - val_acc: 0.3988\n",
      "Epoch 833/1000\n",
      "28709/28709 [==============================] - 15s 523us/step - loss: 0.9383 - acc: 0.9106 - val_loss: 6.3663 - val_acc: 0.4030\n",
      "Epoch 834/1000\n",
      "28709/28709 [==============================] - 8s 285us/step - loss: 0.0079 - acc: 0.9970 - val_loss: 6.5554 - val_acc: 0.3940\n",
      "Epoch 835/1000\n",
      "28709/28709 [==============================] - 13s 436us/step - loss: 0.4353 - acc: 0.9467 - val_loss: 6.2100 - val_acc: 0.3929\n",
      "Epoch 836/1000\n",
      "28709/28709 [==============================] - 12s 426us/step - loss: 0.0070 - acc: 0.9974 - val_loss: 6.3551 - val_acc: 0.3953\n",
      "Epoch 837/1000\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.0095 - acc: 0.9965 - val_loss: 6.4314 - val_acc: 0.4049\n",
      "Epoch 838/1000\n",
      "28709/28709 [==============================] - 15s 517us/step - loss: 0.9218 - acc: 0.9138 - val_loss: 6.4672 - val_acc: 0.4011\n",
      "Epoch 839/1000\n",
      "28709/28709 [==============================] - 9s 317us/step - loss: 0.0077 - acc: 0.9968 - val_loss: 6.5462 - val_acc: 0.4055\n",
      "Epoch 840/1000\n",
      "28709/28709 [==============================] - 11s 399us/step - loss: 0.6458 - acc: 0.9289 - val_loss: 6.2727 - val_acc: 0.4023\n",
      "Epoch 841/1000\n",
      "28709/28709 [==============================] - 13s 457us/step - loss: 0.0073 - acc: 0.9972 - val_loss: 6.6413 - val_acc: 0.4046\n",
      "Epoch 842/1000\n",
      "28709/28709 [==============================] - 8s 280us/step - loss: 0.0891 - acc: 0.9858 - val_loss: 9.1979 - val_acc: 0.3481\n",
      "Epoch 843/1000\n",
      "28709/28709 [==============================] - 15s 525us/step - loss: 0.5346 - acc: 0.9447 - val_loss: 6.2949 - val_acc: 0.4028\n",
      "Epoch 844/1000\n",
      "28709/28709 [==============================] - 11s 380us/step - loss: 0.0385 - acc: 0.9916 - val_loss: 9.1061 - val_acc: 0.3205\n",
      "Epoch 845/1000\n",
      "28709/28709 [==============================] - 11s 368us/step - loss: 0.5303 - acc: 0.9416 - val_loss: 6.4667 - val_acc: 0.4006\n",
      "Epoch 846/1000\n",
      "28709/28709 [==============================] - 15s 533us/step - loss: 0.0080 - acc: 0.9969 - val_loss: 6.9234 - val_acc: 0.3949\n",
      "Epoch 847/1000\n",
      "28709/28709 [==============================] - 9s 326us/step - loss: 0.8156 - acc: 0.9216 - val_loss: 6.3709 - val_acc: 0.4003\n",
      "Epoch 848/1000\n",
      "28709/28709 [==============================] - 13s 442us/step - loss: 0.0068 - acc: 0.9971 - val_loss: 6.4243 - val_acc: 0.3942\n",
      "Epoch 849/1000\n",
      "28709/28709 [==============================] - 13s 462us/step - loss: 0.7654 - acc: 0.9213 - val_loss: 6.3483 - val_acc: 0.4010\n",
      "Epoch 850/1000\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 0.0075 - acc: 0.9971 - val_loss: 6.4957 - val_acc: 0.3932\n",
      "Epoch 851/1000\n",
      "28709/28709 [==============================] - 16s 558us/step - loss: 0.0094 - acc: 0.9965 - val_loss: 7.6611 - val_acc: 0.3830\n",
      "Epoch 852/1000\n",
      "28709/28709 [==============================] - 10s 341us/step - loss: 0.6443 - acc: 0.9337 - val_loss: 6.6352 - val_acc: 0.4034\n",
      "Epoch 853/1000\n",
      "28709/28709 [==============================] - 12s 409us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 6.6748 - val_acc: 0.3958\n",
      "Epoch 854/1000\n",
      "28709/28709 [==============================] - 15s 528us/step - loss: 1.0029 - acc: 0.9085 - val_loss: 6.6520 - val_acc: 0.4006\n",
      "Epoch 855/1000\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 0.0070 - acc: 0.9971 - val_loss: 7.1212 - val_acc: 0.3769\n",
      "Epoch 856/1000\n",
      "28709/28709 [==============================] - 13s 455us/step - loss: 0.6083 - acc: 0.9370 - val_loss: 6.3569 - val_acc: 0.4003\n",
      "Epoch 857/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 13s 442us/step - loss: 0.0068 - acc: 0.9971 - val_loss: 7.0114 - val_acc: 0.3900\n",
      "Epoch 858/1000\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.7067 - acc: 0.9307 - val_loss: 6.4109 - val_acc: 0.4028\n",
      "Epoch 859/1000\n",
      "28709/28709 [==============================] - 15s 506us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 6.5228 - val_acc: 0.3972\n",
      "Epoch 860/1000\n",
      "28709/28709 [==============================] - 11s 372us/step - loss: 1.0461 - acc: 0.9042 - val_loss: 6.4410 - val_acc: 0.3945\n",
      "Epoch 861/1000\n",
      "28709/28709 [==============================] - 11s 368us/step - loss: 0.0081 - acc: 0.9968 - val_loss: 6.4389 - val_acc: 0.4018\n",
      "Epoch 862/1000\n",
      "28709/28709 [==============================] - 15s 523us/step - loss: 0.8625 - acc: 0.9212 - val_loss: 6.3601 - val_acc: 0.4000\n",
      "Epoch 863/1000\n",
      "28709/28709 [==============================] - 9s 320us/step - loss: 0.0081 - acc: 0.9968 - val_loss: 6.3932 - val_acc: 0.4037\n",
      "Epoch 864/1000\n",
      "28709/28709 [==============================] - 12s 425us/step - loss: 0.4543 - acc: 0.9593 - val_loss: 7.5365 - val_acc: 0.3645\n",
      "Epoch 865/1000\n",
      "28709/28709 [==============================] - 13s 464us/step - loss: 0.0842 - acc: 0.9834 - val_loss: 6.5400 - val_acc: 0.3997\n",
      "Epoch 866/1000\n",
      "28709/28709 [==============================] - 9s 329us/step - loss: 0.0072 - acc: 0.9970 - val_loss: 6.9299 - val_acc: 0.3912\n",
      "Epoch 867/1000\n",
      "28709/28709 [==============================] - 13s 448us/step - loss: 0.7873 - acc: 0.9224 - val_loss: 6.4788 - val_acc: 0.3965\n",
      "Epoch 868/1000\n",
      "28709/28709 [==============================] - 13s 459us/step - loss: 0.0071 - acc: 0.9971 - val_loss: 6.5945 - val_acc: 0.3996\n",
      "Epoch 869/1000\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.5412 - acc: 0.9412 - val_loss: 6.6986 - val_acc: 0.3936\n",
      "Epoch 870/1000\n",
      "28709/28709 [==============================] - 14s 500us/step - loss: 0.0080 - acc: 0.9969 - val_loss: 6.6132 - val_acc: 0.3952\n",
      "Epoch 871/1000\n",
      "28709/28709 [==============================] - 11s 396us/step - loss: 0.6141 - acc: 0.9409 - val_loss: 6.4945 - val_acc: 0.3971\n",
      "Epoch 872/1000\n",
      "28709/28709 [==============================] - 10s 359us/step - loss: 0.0072 - acc: 0.9967 - val_loss: 6.7524 - val_acc: 0.4004\n",
      "Epoch 873/1000\n",
      "28709/28709 [==============================] - 15s 526us/step - loss: 0.8306 - acc: 0.9203 - val_loss: 6.5730 - val_acc: 0.3972\n",
      "Epoch 874/1000\n",
      "28709/28709 [==============================] - 8s 285us/step - loss: 0.0076 - acc: 0.9970 - val_loss: 6.6352 - val_acc: 0.3915\n",
      "Epoch 875/1000\n",
      "28709/28709 [==============================] - 13s 469us/step - loss: 0.0086 - acc: 0.9964 - val_loss: 7.1205 - val_acc: 0.3807\n",
      "Epoch 876/1000\n",
      "28709/28709 [==============================] - 13s 443us/step - loss: 0.7615 - acc: 0.9225 - val_loss: 6.5070 - val_acc: 0.4034\n",
      "Epoch 877/1000\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 0.0072 - acc: 0.9970 - val_loss: 6.6150 - val_acc: 0.4007\n",
      "Epoch 878/1000\n",
      "28709/28709 [==============================] - 15s 536us/step - loss: 0.5218 - acc: 0.9423 - val_loss: 6.3690 - val_acc: 0.3975\n",
      "Epoch 879/1000\n",
      "28709/28709 [==============================] - 11s 389us/step - loss: 0.0069 - acc: 0.9974 - val_loss: 6.4486 - val_acc: 0.4028\n",
      "Epoch 880/1000\n",
      " 8192/28709 [=======>......................] - ETA: 11s - loss: 0.0050 - acc: 0.9974"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images,train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_images,test_labels))\n",
    "score = model.evaluate(test_images,test_labels, verbose=0)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7177"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_images)\n",
    "len(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02301867, 0.0011747 , 0.2851315 , 0.03891646, 0.03718293,\n",
       "       0.52093405, 0.09364165], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
